<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Score Based Models 정리본 | 블로그 홈</title><meta name=keywords content><meta name=description content="Score Based Model (Reference)
2011(denoising score matching) https://www.iro.umontreal.ca/~vincentp/Publications/smdae_techreport.pdf 2019(score based generative model) https://arxiv.org/pdf/1907.05600.pdf 2021(score based SDE model) https://arxiv.org/pdf/2011.13456.pdf 2021(SDEdit) https://arxiv.org/pdf/2108.01073.pdf (youtube)
(VAE 강의) https://www.youtube.com/watch?v=o_peo6U7IRM (시립대 강의) https://www.youtube.com/watch?v=HjriJyr8VZ8&amp;list=PLeiav_J6JcY8iFItzNZ_6PMlz9W4_jz5J&amp;index=57 (diffusion 강의) https://www.youtube.com/watch?v=uFoGaIVHfoE Goal of Generative Model 대상으로 하는 데이터들의 실제 분포 $p(x)$가 존재한다고 가정. 이를 데이터들을 가지고, $p(x)$와 $g_{\theta}(x)$가 유사해지도록 파라미터 $\theta$를 학습시킨다. 이후, 새로운 데이터를 생성한다는 것은 학습한 $g_{\theta}$에 $x_0$를 대입하여 $g_{\theta}(x_0)$ 라는 결과물을 sampling하는 것이다. 이때, $p(x)$의 분포를 모를 때(Implicit), 알 때(Explicit)의 경우 파라미터의 학습방법이 달라진다."><meta name=author content="Me"><link rel=canonical href=https://dobe0715.github.io/posts/score-based-model/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Score Based Models 정리본"><meta property="og:description" content="Score Based Model (Reference)
2011(denoising score matching) https://www.iro.umontreal.ca/~vincentp/Publications/smdae_techreport.pdf 2019(score based generative model) https://arxiv.org/pdf/1907.05600.pdf 2021(score based SDE model) https://arxiv.org/pdf/2011.13456.pdf 2021(SDEdit) https://arxiv.org/pdf/2108.01073.pdf (youtube)
(VAE 강의) https://www.youtube.com/watch?v=o_peo6U7IRM (시립대 강의) https://www.youtube.com/watch?v=HjriJyr8VZ8&amp;list=PLeiav_J6JcY8iFItzNZ_6PMlz9W4_jz5J&amp;index=57 (diffusion 강의) https://www.youtube.com/watch?v=uFoGaIVHfoE Goal of Generative Model 대상으로 하는 데이터들의 실제 분포 $p(x)$가 존재한다고 가정. 이를 데이터들을 가지고, $p(x)$와 $g_{\theta}(x)$가 유사해지도록 파라미터 $\theta$를 학습시킨다. 이후, 새로운 데이터를 생성한다는 것은 학습한 $g_{\theta}$에 $x_0$를 대입하여 $g_{\theta}(x_0)$ 라는 결과물을 sampling하는 것이다. 이때, $p(x)$의 분포를 모를 때(Implicit), 알 때(Explicit)의 경우 파라미터의 학습방법이 달라진다."><meta property="og:type" content="article"><meta property="og:url" content="https://dobe0715.github.io/posts/score-based-model/"><meta property="og:image" content="https://dobe0715.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dobe0715.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Score Based Models 정리본"><meta name=twitter:description content="Score Based Model (Reference)
2011(denoising score matching) https://www.iro.umontreal.ca/~vincentp/Publications/smdae_techreport.pdf 2019(score based generative model) https://arxiv.org/pdf/1907.05600.pdf 2021(score based SDE model) https://arxiv.org/pdf/2011.13456.pdf 2021(SDEdit) https://arxiv.org/pdf/2108.01073.pdf (youtube)
(VAE 강의) https://www.youtube.com/watch?v=o_peo6U7IRM (시립대 강의) https://www.youtube.com/watch?v=HjriJyr8VZ8&amp;list=PLeiav_J6JcY8iFItzNZ_6PMlz9W4_jz5J&amp;index=57 (diffusion 강의) https://www.youtube.com/watch?v=uFoGaIVHfoE Goal of Generative Model 대상으로 하는 데이터들의 실제 분포 $p(x)$가 존재한다고 가정. 이를 데이터들을 가지고, $p(x)$와 $g_{\theta}(x)$가 유사해지도록 파라미터 $\theta$를 학습시킨다. 이후, 새로운 데이터를 생성한다는 것은 학습한 $g_{\theta}$에 $x_0$를 대입하여 $g_{\theta}(x_0)$ 라는 결과물을 sampling하는 것이다. 이때, $p(x)$의 분포를 모를 때(Implicit), 알 때(Explicit)의 경우 파라미터의 학습방법이 달라진다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://dobe0715.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Score Based Models 정리본","item":"https://dobe0715.github.io/posts/score-based-model/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Score Based Models 정리본","name":"Score Based Models 정리본","description":"Score Based Model (Reference)\n2011(denoising score matching) https://www.iro.umontreal.ca/~vincentp/Publications/smdae_techreport.pdf 2019(score based generative model) https://arxiv.org/pdf/1907.05600.pdf 2021(score based SDE model) https://arxiv.org/pdf/2011.13456.pdf 2021(SDEdit) https://arxiv.org/pdf/2108.01073.pdf (youtube)\n(VAE 강의) https://www.youtube.com/watch?v=o_peo6U7IRM (시립대 강의) https://www.youtube.com/watch?v=HjriJyr8VZ8\u0026amp;list=PLeiav_J6JcY8iFItzNZ_6PMlz9W4_jz5J\u0026amp;index=57 (diffusion 강의) https://www.youtube.com/watch?v=uFoGaIVHfoE Goal of Generative Model 대상으로 하는 데이터들의 실제 분포 $p(x)$가 존재한다고 가정. 이를 데이터들을 가지고, $p(x)$와 $g_{\\theta}(x)$가 유사해지도록 파라미터 $\\theta$를 학습시킨다. 이후, 새로운 데이터를 생성한다는 것은 학습한 $g_{\\theta}$에 $x_0$를 대입하여 $g_{\\theta}(x_0)$ 라는 결과물을 sampling하는 것이다. 이때, $p(x)$의 분포를 모를 때(Implicit), 알 때(Explicit)의 경우 파라미터의 학습방법이 달라진다.","keywords":[],"articleBody":"Score Based Model (Reference)\n2011(denoising score matching) https://www.iro.umontreal.ca/~vincentp/Publications/smdae_techreport.pdf 2019(score based generative model) https://arxiv.org/pdf/1907.05600.pdf 2021(score based SDE model) https://arxiv.org/pdf/2011.13456.pdf 2021(SDEdit) https://arxiv.org/pdf/2108.01073.pdf (youtube)\n(VAE 강의) https://www.youtube.com/watch?v=o_peo6U7IRM (시립대 강의) https://www.youtube.com/watch?v=HjriJyr8VZ8\u0026list=PLeiav_J6JcY8iFItzNZ_6PMlz9W4_jz5J\u0026index=57 (diffusion 강의) https://www.youtube.com/watch?v=uFoGaIVHfoE Goal of Generative Model 대상으로 하는 데이터들의 실제 분포 $p(x)$가 존재한다고 가정. 이를 데이터들을 가지고, $p(x)$와 $g_{\\theta}(x)$가 유사해지도록 파라미터 $\\theta$를 학습시킨다. 이후, 새로운 데이터를 생성한다는 것은 학습한 $g_{\\theta}$에 $x_0$를 대입하여 $g_{\\theta}(x_0)$ 라는 결과물을 sampling하는 것이다. 이때, $p(x)$의 분포를 모를 때(Implicit), 알 때(Explicit)의 경우 파라미터의 학습방법이 달라진다. 1. Implicit : GAN 사실, GAN은 데이터 분포함수 $p, g$를 학습하는 것이 아니고, 생성해낸 데이터 샘플들의 분포, 즉 $p(X), g(X)$가 비슷해지도록 학습하는 것이다. 판별자(discriminator)를 이용해 결과물이 실제 데이터들의 분포에 해당하는지 판가름하여 생성자(generator)를 학습시킨다. 2. Explicit Explicit이라고해서 p의 분포를 정확히 아는건아니고.. 결국에 알고있는 분포 (Gaussian 분포)로 간접적으로 근사시키는 방법이다.\n진짜로 명백하게 정의하는 모델은 flow모델??\n주된 아이디어는, $p_\\theta(x)$와 주어진 샘플데이터들$(X_1, X_2, …, X_n)$을가지고 가장 잘 설명하는 파라미터 $\\theta$를 찾기위해 log-likelihood를 계산해, 이 값을 최대화하는 값을 찾는 것이다.\n최우추정법(MLE, method of Maximum Likelihood Estimation)\n우도함수 L : likelihood function\n$f(x|\\theta)$ : pdf\n$x_1, x_2, …, x_n$ : 관측값\n$L(\\theta|x_1, x_2, …, x_n) := f(x_1|\\theta)f(x_2|\\theta). ..f(x_n|\\theta)$\n$\\theta^* = \\arg \\max \\limits_{\\theta} \\sum_{i=1}^n(\\log{p_\\theta(x_i)})$ 요러한 파라미터 $\\theta$를 찾는것이 목표 보통은 미분해서 0되는 지점 찾는다.\n2.1 VAE, Diffusion AE(AutoEncoder)\nencoder : image -\u003e latent vector ($x$-\u003e $q_\\phi(x)$)\ndecoder : latent vector -\u003e image ($p_\\theta(q_\\phi(x))$)\n그런데, 이렇게할 경우 자연스럽게도 학습할때 사용하지 않은 이미지에대한 표현력이 떨어진다(discrete하게 mapping했기 때문에) VAE(VariationalAutoEncoder)\nencoder : image -\u003e latent vector ($x$ -\u003e $q_\\phi(z|x)$ -\u003e $z$)\ndecoder : latent vector -\u003e image ($z$ -\u003e$p_\\theta(x|z))$ -\u003e $x$)\n여기서 q, p는 확률함수(위와 구분지어야함) reparameterization trick : $\\epsilon$ ~ $N(0, 1)$, $z = \\mu + \\sigma^2\\epsilon$ -\u003e (continuous하게 mapping해줘서 표현력 좋음)\nLikelihood : $p_\\theta(x) = \\int{p_\\theta(x|z)p_\\theta(z)}dz$ 이걸 최대화 하는 $\\theta$찾기!(by ELBO)\n여기서 p_theta를 계산할 수 없어서 위의 적분식에 q_phi를 이용해 수식 쭉쭉 전개해나가서 아래와 같은 식을 유도한다. 수식유도 꼭 해보기 Diffusion\nVAE와 상당히 비슷한 느낌. VAE에서는 encoder로부터 나온결과에 노이즈추가했다면\n여기선 이전time step과 noise를 interpolation해줌으로써, 적은양의 noise를 time step마다 추가해줘서 가우시안분포까지 확산(diffuse)시킨다, 다음에 그것들을 denoising해준다. 이것을 학습시켜서 가우시안분포로부터 sampling해서 이미지를 생성\n마르코프체인을 가정해서 확률함수를 정의하고, 그것으로 likelihood를 최대화 하는 파라미터 계산\n생성모델들 그림 Score based Model Energe Based Model(EBM) 어떤 x로부터의 분포 y가 있다고 하자. ex) $y=x^2$ 이를 파라미터를 통해 표현하면, $E_\\theta(x)=x^2$과 같이 볼 수 있다. 이를 확률함수로 만들어준다. $p_\\theta(x)=\\cfrac{e^{-E_\\theta(x)}}{z_\\theta}$, $\\int{p_\\theta(x)}dx = 1$ 이제, 이 p에대해 likelihood를 최대화한다!!\nScore Matching Score : $\\nabla{x}\\log{p(x)}$값.(데이터들의 확률함수의 log-likelihood의 gradient값) traditional한 방법 : $\\arg\\min\\limits_{\\theta}\\mathbb{E}{p(x)}\\frac{1}{2}[||\\nabla{x} \\log{p(x)} - S\\theta(x)||_2^2]$ Denoising Score Matching 기본 idea : 알고있는 분포 q를 이용해(보통 Gaussian 분포) x에 Noise($\\sigma$)를 추가한 데이터의 분포를 $q_\\sigma(\\tilde{x}, x)$라 정의하고, 이놈을 이용해 score를 정의한다. $$q_\\sigma(\\tilde{x}, x) = q_\\sigma(\\tilde{x}|x)q_0(x)$$\n$q_\\sigma(\\tilde{x}, x)$ : noise가 추가된 데이터 분포 $q_\\sigma(\\tilde{x}|x)$ : noise 분포 $q_0(x)$ : 원래 분포 $q_\\sigma(\\tilde{x}) = \\int{q_\\sigma(\\tilde{x}, x)}dx = \\int{q_\\sigma(\\tilde{x}|x)q_0(x)}dx \\simeq \\int{q_\\sigma(\\tilde{x}|x)p_{data}(x)}dx$\n이때, $\\sigma$가 충분히 작으면 위와같이 근사할 수 있다고함. (당연히도 noise가 충분히 작다면 원본이미지와 그게 다르지 않을것이라.. diffusion 모델에서 작은 noise추가할 때 가정한 것과 같은원리)\n이제, 목적함수를 정의하자. $\\sigma$를 크기순으로 나열해서,\n$\\sigma_{min}=\\sigma_1 \u003c \\sigma_2 \u003c … \u003c \\sigma_{N}=\\sigma_{max}$ $p_{data} \\simeq p_{\\sigma_{min}}, p_{\\sigma_i}(\\tilde{x}|x) = N(\\tilde{x};x, \\sigma_i^2)$으로부터 $\\theta^* = \\arg\\min\\limits_{\\theta} \\sum_{i=1}^N{\\sigma^2 \\mathbb{E}{p{data}}\\mathbb{E}{p{\\sigma_i}(\\tilde{x}, x)}[||S_\\theta(\\tilde{x},\\sigma_i)-\\nabla_{\\tilde{x}}\\log{p_i}(\\tilde{x}|x)||2^2]}$를 계산한다. 이 때, $-\\nabla{\\tilde{x}}\\log{p{\\sigma_i}}(\\tilde{x}|x) \\simeq \\cfrac{\\tilde{x}-x}{\\sigma_{i}^2}$ : Gaussian Kernel로 근사하여 계산할 수 있다. Sampling with Langevin Dynamics Langevin Dynamics : 주어진 데이터 x의 score를 알고 있을 때, $z_t\\sim N(0, 1), \\epsilon$을 이용해, $x_t = x_{t-1} + \\frac{\\epsilon}{2}\\nabla_x\\log{p(x_{t-1})} + \\sqrt{\\epsilon}z_t$의 연산을 반복수행한다. 이 때, 잘 학습되었다는 가정하에 $x_t = x_{t-1} + \\frac{\\epsilon}{2}s_\\theta(x_{t-1}) + \\sqrt{\\epsilon}z_t$을 통해 sampling을 해준다!! NOTE: Markov Chain Monte Carlo, MCMC\nMonte Carlo : 통계를 통해 시뮬레이션 수행하여 원하는 값을 얻는 기법 원주율 계산 : 찍는 점의 개수를 늘려가며 원주율 근사한다. Markov Chain : 현재 state가 바로 직전 state의 영향만 받는 확률 과정 $$p(x_t|x_{t-1}, x_{t-2}, …, x_0) = p(x_t|x_{t_1})$$ Score based Generative modeling through SDEs (2021) score를 SDE를 통해 접근한다. Recall to DDPM Forward Process 원본이미지 $x_0$에 미세한 Gaussian noise를 hierarchical하게 추가해주는 과정이다. 각 time step에 대해서는\n$q(x_t|x_{t-1}) = N(x_t; \\sqrt{1-\\beta_t}x_{t-1}, \\beta_t 𝐈)$ $x_{t-1}$에 $\\sqrt{1-\\beta}$만큼 곱해놓고 $\\beta_t$ 만큼의 분산을 통해 sampling하는 것이 곧, $x_t$에 noise를 추가한 것이 된다. $\\beta$값이 커질 수록, noise가 커진다고 이해할 수 있다.(여기선, 0.0001~0.02로 고정함) 이 때, 마르코프 연쇄에 의해\n$q(x_{1:T}|x_0) = \\Pi_{t=1}^{T} q(x_t|x_{t-1})$ 를 만족한다. Reverse Process Noise가 추가되어있는 $x_T$로부터 denoising을 해주는 과정이다. 각 time step에 대해 전통 diffusion\n$p_\\theta(x_{t-1}|x_t) = N(x_{t-1};\\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t, t))$ 각 time t에대한 평균과 분산을 예측하게만드는 파라미터 $\\theta$를 학습해야한다. DDPM reverse process\n$\\Sigma_\\theta(x_t, t) = \\sigma_t^2I$ $\\sigma_t^2 = \\tilde{\\beta_t} = \\cfrac{1-\\tilde{\\alpha}_{t-1}}{1-\\tilde{\\alpha}_t} \\beta_t$ or $\\sigma_t^2 = \\beta_t$ ($\\beta_t$ 에 의존하기 때문에 변경) $\\mu_\\theta(x_t, t) = \\cfrac{1}{\\sqrt{\\bar\\alpha_t}}\\bigg(x_t - \\cfrac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}t}}\\epsilon\\theta(x_t, t)\\bigg)$ 평균값$\\mu$을 구하는 것이아니라, 잔차$\\epsilon$를 구하자! -\u003e U-Net 사용 잔차를 통해 $\\mu$를 구할 수 있고, $x_{t-1}$을 샘플링할 수 있다. 마르코프 연쇄에 의해,\n$p_\\theta(x_{0:T}) = p(x_T)\\Pi_{t=1}^T p_\\theta(x_{t-1}|x_t)$ Loss Function 전통 diffusion\n$\\mathbb{E}q\\bigg[D{KL}(q(x_T|x_0) || p(x_T)) + \\sum_{t\u003e1}{D_{KL}(q(x_{t-1}|x_t, x_0) || p_\\theta(x_{t-1}|x_t)) - \\log(p_\\theta(x_0|x_1))}\\bigg]$ DDPM\n$\\mathbb{E}q\\bigg[\\sum{t\u003e1}{D_{KL}(q(x_{t-1}|x_t, x_0) || p_\\theta(x_{t-1}|x_t)) - \\log(p_\\theta(x_0|x_1))}\\bigg]$ regularization term을 제거하고, 위에서 정의한 관계식으로 정리하면, 다음과같이 단순화 할 수 있다.\n$\\mathbb{E}{t, x_0, \\epsilon}\\bigg[||\\epsilon - \\epsilon\\theta(\\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\epsilon, t)||^2\\bigg]$, $\\epsilon \\sim \\mathcal{N}(0, I)$ 수식 유도 차근차근 스스로 해보기!\n어쨌든, 위의 수식으로부터, $\\epsilon_\\theta = s_\\theta$라고 보면,\nsampling과정을 다음과같이 표현할 수 있다.\n$x_{i-1} = \\cfrac{1}{\\sqrt{1-\\beta_i}}(x_i + \\beta_i s_\\theta * (x_i, i)) + \\sqrt{\\beta_i}z_i$, $i = N, N-1, …, 1$ SDE 관점에서 해석 주가예측 연속시간모형에도 사용된 방정식이라고함.. (Ornstein-Uhlenbeck process) https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process $$d\\mathbf{x} = \\mathbf{f}(\\mathbf{x}, t)dt + g(t)d\\mathbf{w}$$\n$t$ : continuous time, ${x(t)}_{t=0}^T$ : diffusion process간 x값\n$x(0) \\sim p_0$, $x(T) \\sim p_T$ : i.i.d samples\n$\\mathbf{w}$ : Standard Wiener process(Brownian motion)\nt에 대한 noise term, 위의 $\\sigma$역할 t에 따라, $w_{t+\\vartriangle{t}} - w_t : \\Omega \\rightarrow \\mathbb{R}^d$, $w_{t+\\vartriangle{t}} \\sim \\mathcal{N}(0, \\vartriangle{t})$ $f(\\cdot, t) : \\mathbb{R}^d \\rightarrow \\mathbb{R}^d$ : x 에 대한 drift coefficient function\n시간에 대한 추세(경향)을 반영햔 term $g(\\cdot) : \\mathbb{R} \\rightarrow \\mathbb{R}$ : $x(t)$에 대한 diffusion coefficient function\n이 때, g는 x와 독립이어야 한다. 어쨌거나, 위와같이 표현된 식은 다음의 식으로 reverse가 가능하다고한다. $$d\\mathbf{x} = \\bigg[\\mathbf{f}(\\mathbf{x}, t) - g(t)^2\\bigtriangledown_x\\log{p_t(\\mathbf{x})}\\bigg]dt + g(t)d\\mathbf{w}$$ $0","wordCount":"1004","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://dobe0715.github.io/posts/score-based-model/"},"publisher":{"@type":"Organization","name":"블로그 홈","logo":{"@type":"ImageObject","url":"https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dobe0715.github.io accesskey=h title="Home (Alt + H)"><img src=https://dobe0715.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://dobe0715.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://dobe0715.github.io/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dobe0715.github.io>Home</a>&nbsp;»&nbsp;<a href=https://dobe0715.github.io/posts/>Posts</a></div><h1 class=post-title>Score Based Models 정리본</h1><div class=post-meta>5 min&nbsp;·&nbsp;1004 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/Score%20Based%20Model.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><h1 id=score-based-model>Score Based Model<a hidden class=anchor aria-hidden=true href=#score-based-model>#</a></h1><p><strong>(Reference)</strong></p><ul><li>2011(denoising score matching) <a href=https://www.iro.umontreal.ca/~vincentp/Publications/smdae_techreport.pdf>https://www.iro.umontreal.ca/~vincentp/Publications/smdae_techreport.pdf</a></li><li>2019(score based generative model) <a href=https://arxiv.org/pdf/1907.05600.pdf>https://arxiv.org/pdf/1907.05600.pdf</a></li><li>2021(score based SDE model) <a href=https://arxiv.org/pdf/2011.13456.pdf>https://arxiv.org/pdf/2011.13456.pdf</a></li><li>2021(SDEdit) <a href=https://arxiv.org/pdf/2108.01073.pdf>https://arxiv.org/pdf/2108.01073.pdf</a></li></ul><p><strong>(youtube)</strong></p><ul><li>(VAE 강의) <a href="https://www.youtube.com/watch?v=o_peo6U7IRM">https://www.youtube.com/watch?v=o_peo6U7IRM</a></li><li>(시립대 강의) <a href="https://www.youtube.com/watch?v=HjriJyr8VZ8&amp;list=PLeiav_J6JcY8iFItzNZ_6PMlz9W4_jz5J&amp;index=57">https://www.youtube.com/watch?v=HjriJyr8VZ8&amp;list=PLeiav_J6JcY8iFItzNZ_6PMlz9W4_jz5J&amp;index=57</a></li><li>(diffusion 강의) <a href="https://www.youtube.com/watch?v=uFoGaIVHfoE">https://www.youtube.com/watch?v=uFoGaIVHfoE</a></li></ul><h2 id=goal-of-generative-model>Goal of Generative Model<a hidden class=anchor aria-hidden=true href=#goal-of-generative-model>#</a></h2><ul><li>대상으로 하는 데이터들의 실제 분포 $p(x)$가 존재한다고 가정.</li><li>이를 데이터들을 가지고, $p(x)$와 $g_{\theta}(x)$가 유사해지도록 파라미터 $\theta$를 학습시킨다.</li><li>이후, 새로운 데이터를 생성한다는 것은 학습한 $g_{\theta}$에 $x_0$를 대입하여 $g_{\theta}(x_0)$ 라는 결과물을 sampling하는 것이다.</li><li>이때, $p(x)$의 분포를 모를 때(Implicit), 알 때(Explicit)의 경우 파라미터의 학습방법이 달라진다.</li></ul><h3 id=1-implicit--gan>1. Implicit : GAN<a hidden class=anchor aria-hidden=true href=#1-implicit--gan>#</a></h3><ul><li>사실, GAN은 데이터 분포함수 $p, g$를 학습하는 것이 아니고,</li><li>생성해낸 데이터 샘플들의 분포, 즉 $p(X), g(X)$가 비슷해지도록 학습하는 것이다.<ul><li>판별자(discriminator)를 이용해 결과물이 실제 데이터들의 분포에 해당하는지 판가름하여 생성자(generator)를 학습시킨다.</li></ul></li></ul><h3 id=2-explicit>2. Explicit<a hidden class=anchor aria-hidden=true href=#2-explicit>#</a></h3><ul><li><p>Explicit이라고해서 p의 분포를 정확히 아는건아니고.. 결국에 알고있는 분포 (Gaussian 분포)로 간접적으로 근사시키는 방법이다.</p></li><li><p>진짜로 명백하게 정의하는 모델은 flow모델??</p></li><li><p>주된 아이디어는, $p_\theta(x)$와 주어진 샘플데이터들$(X_1, X_2, &mldr;, X_n)$을가지고 가장 잘 설명하는 파라미터 $\theta$를 찾기위해 log-likelihood를 계산해, 이 값을 최대화하는 값을 찾는 것이다.</p></li><li><p><strong>최우추정법(MLE, method of Maximum Likelihood Estimation)</strong></p></li><li><p>우도함수 L : likelihood function</p></li><li><p>$f(x|\theta)$ : pdf</p></li><li><p>$x_1, x_2, &mldr;, x_n$ : 관측값</p></li><li><p>$L(\theta|x_1, x_2, &mldr;, x_n) := f(x_1|\theta)f(x_2|\theta). ..f(x_n|\theta)$</p></li></ul><p>$\theta^* = \arg \max \limits_{\theta} \sum_{i=1}^n(\log{p_\theta(x_i)})$
요러한 파라미터 $\theta$를 찾는것이 목표
보통은 미분해서 0되는 지점 찾는다.</p><h4 id=21-vae-diffusion>2.1 VAE, Diffusion<a hidden class=anchor aria-hidden=true href=#21-vae-diffusion>#</a></h4><ul><li><p><strong>AE(AutoEncoder)</strong></p></li><li><p>encoder : image -> latent vector ($x$-> $q_\phi(x)$)</p></li><li><p>decoder : latent vector -> image ($p_\theta(q_\phi(x))$)</p><ul><li>그런데, 이렇게할 경우 자연스럽게도 학습할때 사용하지 않은 이미지에대한 표현력이 떨어진다(discrete하게 mapping했기 때문에)</li></ul></li><li><p><strong>VAE(VariationalAutoEncoder)</strong></p></li><li><p>encoder : image -> latent vector ($x$ -> $q_\phi(z|x)$ -> $z$)</p></li><li><p>decoder : latent vector -> image ($z$ ->$p_\theta(x|z))$ -> $x$)</p><ul><li>여기서 q, p는 확률함수(위와 구분지어야함)</li></ul></li><li><p>reparameterization trick : $\epsilon$ ~ $N(0, 1)$, $z = \mu + \sigma^2\epsilon$ -> (continuous하게 mapping해줘서 표현력 좋음)</p></li><li><p>Likelihood : $p_\theta(x) = \int{p_\theta(x|z)p_\theta(z)}dz$ 이걸 최대화 하는 $\theta$찾기!(by ELBO)</p><ul><li>여기서 p_theta를 계산할 수 없어서 위의 적분식에 q_phi를 이용해 수식 쭉쭉 전개해나가서 아래와 같은 식을 유도한다.</li><li><strong>수식유도 꼭 해보기</strong></li></ul></li><li><p><strong>Diffusion</strong></p></li><li><p>VAE와 상당히 비슷한 느낌. VAE에서는 encoder로부터 나온결과에 노이즈추가했다면</p></li><li><p>여기선 이전time step과 noise를 interpolation해줌으로써, 적은양의 noise를 time step마다 추가해줘서 가우시안분포까지 확산(diffuse)시킨다, 다음에 그것들을 denoising해준다. 이것을 학습시켜서 가우시안분포로부터 sampling해서 이미지를 생성</p></li><li><p>마르코프체인을 가정해서 확률함수를 정의하고, 그것으로 likelihood를 최대화 하는 파라미터 계산</p></li></ul><p><strong>생성모델들 그림</strong></p><h1 id=score-based-model-1>Score based Model<a hidden class=anchor aria-hidden=true href=#score-based-model-1>#</a></h1><h4 id=energe-based-modelebm>Energe Based Model(EBM)<a hidden class=anchor aria-hidden=true href=#energe-based-modelebm>#</a></h4><ul><li>어떤 x로부터의 분포 y가 있다고 하자. ex) $y=x^2$</li><li>이를 파라미터를 통해 표현하면, $E_\theta(x)=x^2$과 같이 볼 수 있다.</li><li>이를 확률함수로 만들어준다. $p_\theta(x)=\cfrac{e^{-E_\theta(x)}}{z_\theta}$, $\int{p_\theta(x)}dx = 1$</li></ul><p>이제, 이 p에대해 likelihood를 최대화한다!!</p><h4 id=score-matching>Score Matching<a hidden class=anchor aria-hidden=true href=#score-matching>#</a></h4><ul><li><strong>Score</strong> : $\nabla{x}\log{p(x)}$값.(데이터들의 확률함수의 log-likelihood의 gradient값)</li><li>traditional한 방법 : $\arg\min\limits_{\theta}\mathbb{E}<em>{p(x)}\frac{1}{2}[||\nabla{x}
\log{p(x)} - S</em>\theta(x)||_2^2]$</li></ul><h4 id=denoising-score-matching>Denoising Score Matching<a hidden class=anchor aria-hidden=true href=#denoising-score-matching>#</a></h4><ul><li>기본 idea : 알고있는 분포 q를 이용해(보통 Gaussian 분포) x에 Noise($\sigma$)를 추가한 데이터의 분포를 $q_\sigma(\tilde{x}, x)$라 정의하고, 이놈을 이용해 score를 정의한다.</li></ul><p>$$q_\sigma(\tilde{x}, x) = q_\sigma(\tilde{x}|x)q_0(x)$$</p><ul><li>$q_\sigma(\tilde{x}, x)$ : noise가 추가된 데이터 분포</li><li>$q_\sigma(\tilde{x}|x)$ : noise 분포</li><li>$q_0(x)$ : 원래 분포</li></ul><p>$q_\sigma(\tilde{x}) = \int{q_\sigma(\tilde{x}, x)}dx = \int{q_\sigma(\tilde{x}|x)q_0(x)}dx \simeq \int{q_\sigma(\tilde{x}|x)p_{data}(x)}dx$<br>이때, $\sigma$가 충분히 작으면 위와같이 근사할 수 있다고함.
(당연히도 noise가 충분히 작다면 원본이미지와 그게 다르지 않을것이라.. diffusion 모델에서 작은 noise추가할 때 가정한 것과 같은원리)</p><p>이제, 목적함수를 정의하자.
$\sigma$를 크기순으로 나열해서,</p><ul><li>$\sigma_{min}=\sigma_1 &lt; \sigma_2 &lt; &mldr; &lt; \sigma_{N}=\sigma_{max}$</li><li>$p_{data} \simeq p_{\sigma_{min}}, p_{\sigma_i}(\tilde{x}|x) = N(\tilde{x};x, \sigma_i^2)$으로부터</li><li>$\theta^* = \arg\min\limits_{\theta} \sum_{i=1}^N{\sigma^2 \mathbb{E}<em>{p</em>{data}}\mathbb{E}<em>{p</em>{\sigma_i}(\tilde{x}, x)}[||S_\theta(\tilde{x},\sigma_i)-\nabla_{\tilde{x}}\log{p_i}(\tilde{x}|x)||<em>2^2]}$를 계산한다.
이 때, $-\nabla{\tilde{x}}\log{p</em>{\sigma_i}}(\tilde{x}|x) \simeq \cfrac{\tilde{x}-x}{\sigma_{i}^2}$ : Gaussian Kernel로 근사하여 계산할 수 있다.</li></ul><h4 id=sampling-with-langevin-dynamics>Sampling with Langevin Dynamics<a hidden class=anchor aria-hidden=true href=#sampling-with-langevin-dynamics>#</a></h4><ul><li>Langevin Dynamics : 주어진 데이터 x의 score를 알고 있을 때,</li><li>$z_t\sim N(0, 1), \epsilon$을 이용해,</li><li>$x_t = x_{t-1} + \frac{\epsilon}{2}\nabla_x\log{p(x_{t-1})} + \sqrt{\epsilon}z_t$의 연산을 반복수행한다.
이 때, 잘 학습되었다는 가정하에</li><li>$x_t = x_{t-1} + \frac{\epsilon}{2}s_\theta(x_{t-1}) + \sqrt{\epsilon}z_t$을 통해 sampling을 해준다!!</li></ul><p><strong>NOTE</strong>: Markov Chain Monte Carlo, MCMC</p><ul><li>Monte Carlo : 통계를 통해 시뮬레이션 수행하여 원하는 값을 얻는 기법<ul><li>원주율 계산 : 찍는 점의 개수를 늘려가며 원주율 근사한다.</li><li></li></ul></li><li>Markov Chain : 현재 state가 바로 직전 state의 영향만 받는 확률 과정
$$p(x_t|x_{t-1}, x_{t-2}, &mldr;, x_0) = p(x_t|x_{t_1})$$</li></ul><h1 id=score-based-generative-modeling-through-sdes>Score based Generative modeling through SDEs<a hidden class=anchor aria-hidden=true href=#score-based-generative-modeling-through-sdes>#</a></h1><ul><li>(2021) score를 SDE를 통해 접근한다.</li></ul><h2 id=recall-to-ddpm>Recall to DDPM<a hidden class=anchor aria-hidden=true href=#recall-to-ddpm>#</a></h2><h3 id=forward-process>Forward Process<a hidden class=anchor aria-hidden=true href=#forward-process>#</a></h3><ul><li>원본이미지 $x_0$에 미세한 Gaussian noise를 hierarchical하게 추가해주는 과정이다.</li></ul><p>각 time step에 대해서는</p><ul><li>$q(x_t|x_{t-1}) = N(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t 𝐈)$<ul><li>$x_{t-1}$에 $\sqrt{1-\beta}$만큼 곱해놓고 $\beta_t$ 만큼의 분산을 통해 sampling하는 것이 곧, $x_t$에 noise를 추가한 것이 된다.</li><li>$\beta$값이 커질 수록, noise가 커진다고 이해할 수 있다.(여기선, 0.0001~0.02로 고정함)</li></ul></li></ul><p>이 때, 마르코프 연쇄에 의해</p><ul><li>$q(x_{1:T}|x_0) = \Pi_{t=1}^{T} q(x_t|x_{t-1})$
를 만족한다.</li></ul><h3 id=reverse-process>Reverse Process<a hidden class=anchor aria-hidden=true href=#reverse-process>#</a></h3><ul><li>Noise가 추가되어있는 $x_T$로부터 denoising을 해주는 과정이다.</li></ul><p>각 time step에 대해
전통 diffusion</p><ul><li>$p_\theta(x_{t-1}|x_t) = N(x_{t-1};\mu_\theta(x_t, t), \Sigma_\theta(x_t, t))$<ul><li>각 time t에대한 평균과 분산을 예측하게만드는 파라미터 $\theta$를 학습해야한다.</li></ul></li></ul><p>DDPM reverse process</p><ul><li>$\Sigma_\theta(x_t, t) = \sigma_t^2I$</li><li>$\sigma_t^2 = \tilde{\beta_t} = \cfrac{1-\tilde{\alpha}_{t-1}}{1-\tilde{\alpha}_t} \beta_t$ or $\sigma_t^2 = \beta_t$<ul><li>($\beta_t$ 에 의존하기 때문에 변경)</li></ul></li><li>$\mu_\theta(x_t, t) = \cfrac{1}{\sqrt{\bar\alpha_t}}\bigg(x_t - \cfrac{\beta_t}{\sqrt{1-\bar{\alpha}<em>t}}\epsilon</em>\theta(x_t, t)\bigg)$<ul><li>평균값$\mu$을 구하는 것이아니라, 잔차$\epsilon$를 구하자! -> U-Net 사용</li><li>잔차를 통해 $\mu$를 구할 수 있고, $x_{t-1}$을 샘플링할 수 있다.</li></ul></li></ul><p>마르코프 연쇄에 의해,</p><ul><li>$p_\theta(x_{0:T}) = p(x_T)\Pi_{t=1}^T p_\theta(x_{t-1}|x_t)$</li></ul><h3 id=loss-function>Loss Function<a hidden class=anchor aria-hidden=true href=#loss-function>#</a></h3><p>전통 diffusion</p><ul><li>$\mathbb{E}<em>q\bigg[D</em>{KL}(q(x_T|x_0) || p(x_T)) + \sum_{t>1}{D_{KL}(q(x_{t-1}|x_t, x_0) || p_\theta(x_{t-1}|x_t)) - \log(p_\theta(x_0|x_1))}\bigg]$</li></ul><p>DDPM</p><ul><li>$\mathbb{E}<em>q\bigg[\sum</em>{t>1}{D_{KL}(q(x_{t-1}|x_t, x_0) || p_\theta(x_{t-1}|x_t)) - \log(p_\theta(x_0|x_1))}\bigg]$<ul><li>regularization term을 제거하고, 위에서 정의한 관계식으로 정리하면,</li></ul></li></ul><p>다음과같이 단순화 할 수 있다.</p><ul><li>$\mathbb{E}<em>{t, x_0, \epsilon}\bigg[||\epsilon - \epsilon</em>\theta(\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1 - \bar{\alpha}_t}\epsilon, t)||^2\bigg]$, $\epsilon \sim \mathcal{N}(0, I)$</li></ul><p><strong>수식 유도 차근차근 스스로 해보기!</strong></p><p>어쨌든, 위의 수식으로부터, $\epsilon_\theta = s_\theta$라고 보면,</p><p>sampling과정을 다음과같이 표현할 수 있다.</p><ul><li>$x_{i-1} = \cfrac{1}{\sqrt{1-\beta_i}}(x_i + \beta_i s_\theta * (x_i, i)) + \sqrt{\beta_i}z_i$, $i = N, N-1, &mldr;, 1$</li></ul><h2 id=sde-관점에서-해석>SDE 관점에서 해석<a hidden class=anchor aria-hidden=true href=#sde-관점에서-해석>#</a></h2><ul><li>주가예측 연속시간모형에도 사용된 방정식이라고함..
(Ornstein-Uhlenbeck process) <a href=https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process>https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process</a></li></ul><p>$$d\mathbf{x} = \mathbf{f}(\mathbf{x}, t)dt + g(t)d\mathbf{w}$$</p><ul><li><p>$t$ : continuous time, ${x(t)}_{t=0}^T$ : diffusion process간 x값</p></li><li><p>$x(0) \sim p_0$, $x(T) \sim p_T$ : i.i.d samples</p></li><li><p>$\mathbf{w}$ : Standard Wiener process(<em>Brownian motion</em>)</p><ul><li>t에 대한 noise term, 위의 $\sigma$역할</li><li>t에 따라, $w_{t+\vartriangle{t}} - w_t : \Omega \rightarrow \mathbb{R}^d$, $w_{t+\vartriangle{t}} \sim \mathcal{N}(0, \vartriangle{t})$</li></ul></li><li><p>$f(\cdot, t) : \mathbb{R}^d \rightarrow \mathbb{R}^d$ : x 에 대한 drift coefficient function</p><ul><li>시간에 대한 추세(경향)을 반영햔 term</li></ul></li><li><p>$g(\cdot) : \mathbb{R} \rightarrow \mathbb{R}$ : $x(t)$에 대한 diffusion coefficient function</p><ul><li>이 때, g는 x와 독립이어야 한다.</li></ul></li></ul><p>어쨌거나, 위와같이 표현된 식은 다음의 식으로 reverse가 가능하다고한다.
$$d\mathbf{x} = \bigg[\mathbf{f}(\mathbf{x}, t) - g(t)^2\bigtriangledown_x\log{p_t(\mathbf{x})}\bigg]dt + g(t)d\mathbf{w}$$
$0&lt;s&lt;t&lt;T$, $p_{st}(x(t)|x(s))$</p><h3 id=smldscore-matching-langevin-dynamics>SMLD(score matching langevin dynamics)<a hidden class=anchor aria-hidden=true href=#smldscore-matching-langevin-dynamics>#</a></h3><h4 id=forward-process-1>Forward process<a hidden class=anchor aria-hidden=true href=#forward-process-1>#</a></h4><p>$p_{\sigma_i}(\tilde{x}|x) = N(\tilde{x};x, \sigma_i^2)$로부터,
$x_i = x_{i-1} + \sqrt{\sigma_i^2 - \sigma_{i-1}^2}z_{i-1}$를 끌어올 수 있고, 이로부터 미분방정식을 유도하면,(오일러 메소드)</p><p>$dx = \sqrt{\cfrac{d[\sigma^2(t)]}{dt}}dw$</p><p>이는 위의 구조와 동일하다.</p><h4 id=reverse-process-1>reverse process<a hidden class=anchor aria-hidden=true href=#reverse-process-1>#</a></h4><p>수식유도가.. 다음에 해봐야할듯</p><h3 id=ddpm>DDPM<a hidden class=anchor aria-hidden=true href=#ddpm>#</a></h3><h4 id=forward-process-2>Forward process<a hidden class=anchor aria-hidden=true href=#forward-process-2>#</a></h4><p>$q(x_t|x_{t-1}) = N(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t I)$로부터,
$x_t = \sqrt{1-\beta_t}x_{t-1} + \sqrt{\beta}z_{t-1}$를 끌어올 수 있고, 이로부터 미분방정식을 유도하면,(오일러 메소드)</p><p>$dx = -\cfrac{1}{2}\beta(t)xdt + \sqrt{\beta(t)}dw$</p><h4 id=reverse-process-2>Reverse process<a hidden class=anchor aria-hidden=true href=#reverse-process-2>#</a></h4><p>이것도 유도가&mldr; 다음에</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://dobe0715.github.io/posts/neural-ode/><span class=title>« Prev</span><br><span>Neural Ordinary Differential Equations review</span></a>
<a class=next href=https://dobe0715.github.io/posts/sdedit/><span class=title>Next »</span><br><span>SDEdit 실습</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Score Based Models 정리본 on twitter" href="https://twitter.com/intent/tweet/?text=Score%20Based%20Models%20%ec%a0%95%eb%a6%ac%eb%b3%b8&amp;url=https%3a%2f%2fdobe0715.github.io%2fposts%2fscore-based-model%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Score Based Models 정리본 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fdobe0715.github.io%2fposts%2fscore-based-model%2f&amp;title=Score%20Based%20Models%20%ec%a0%95%eb%a6%ac%eb%b3%b8&amp;summary=Score%20Based%20Models%20%ec%a0%95%eb%a6%ac%eb%b3%b8&amp;source=https%3a%2f%2fdobe0715.github.io%2fposts%2fscore-based-model%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Score Based Models 정리본 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fdobe0715.github.io%2fposts%2fscore-based-model%2f&title=Score%20Based%20Models%20%ec%a0%95%eb%a6%ac%eb%b3%b8"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Score Based Models 정리본 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fdobe0715.github.io%2fposts%2fscore-based-model%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Score Based Models 정리본 on whatsapp" href="https://api.whatsapp.com/send?text=Score%20Based%20Models%20%ec%a0%95%eb%a6%ac%eb%b3%b8%20-%20https%3a%2f%2fdobe0715.github.io%2fposts%2fscore-based-model%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Score Based Models 정리본 on telegram" href="https://telegram.me/share/url?text=Score%20Based%20Models%20%ec%a0%95%eb%a6%ac%eb%b3%b8&amp;url=https%3a%2f%2fdobe0715.github.io%2fposts%2fscore-based-model%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Score Based Models 정리본 on ycombinator" href="https://news.ycombinator.com/submitlink?t=Score%20Based%20Models%20%ec%a0%95%eb%a6%ac%eb%b3%b8&u=https%3a%2f%2fdobe0715.github.io%2fposts%2fscore-based-model%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://dobe0715.github.io>블로그 홈</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
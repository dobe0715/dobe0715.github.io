<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on ë¸”ë¡œê·¸ í™ˆ</title>
    <link>https://dobe0715.github.io/posts/</link>
    <description>Recent content in Posts on ë¸”ë¡œê·¸ í™ˆ</description>
    <image>
      <title>ë¸”ë¡œê·¸ í™ˆ</title>
      <url>https://dobe0715.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://dobe0715.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language><atom:link href="https://dobe0715.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://dobe0715.github.io/posts/adain-style-transfer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/adain-style-transfer/</guid>
      <description>paper review : Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization ì ì‘í˜• instance normalizationì„ ì´ìš©í•´ ì„ì˜ì˜ style transferë¥¼ ì§„í–‰í•˜ëŠ” ëª¨ë¸ 1. ê¸°ì¡´ ëª¨ë¸ ë¶„ì„(neural style transfer) 1.1 Content Loss ê·¸ë¦¼ì˜ ë‚´ìš©(ë¬¼ì²´ì˜ í˜•íƒœ, ìœ„ì¹˜)ì— ëŒ€í•œ ëª©ì í•¨ìˆ˜ $$L_{content}(\vec{p}, \vec{x}, l) = \cfrac{1}{2} \sum_{i, j}({F^l_{ij} - P^l_{ij}})^2$$
1.2 Style Loss ê·¸ë¦¼ì˜ ìŠ¤íƒ€ì¼ì— ëŒ€í•œ ëª©ì í•¨ìˆ˜ Gram matrix $$G^l \in R^{N_l \times N_l}$$ $$G^l_{ij} = \sum_k{F^l_{ik} F^l_{jk}}$$
$l$ë²ˆì§¸ ë ˆì´ì–´ì˜ $i$ì™€$j$ë²ˆì§¸ feature mapì˜ correlationì„ íŒŒì•…í•˜ëŠ” ì²™ë„.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dobe0715.github.io/posts/classification-cnn-models/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/classification-cnn-models/</guid>
      <description>Inception Net(GoogLeNet) https://arxiv.org/pdf/1409.4842.pdf ì°¸ê³  ë¸”ë¡œê·¸ https://phil-baek.tistory.com/entry/3-GoogLeNet-Going-deeper-with-convolutions-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0 ëª¨ë¸ ë‚˜ì˜¤ê²Œ ëœ ë°°ê²½ DNNì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²• ê°€ì¥ ì§ì ‘ì ì¸ ë°©ë²•ì€ sizeë¥¼ ëŠ˜ë¦¬ëŠ” ê²ƒì—ì„œ ì‹œì‘
êµ¬ì²´ì ìœ¼ë¡œ, depth/widthë¥¼ ì¦ê°€ì‹œí‚¤ë©´ ë˜ëŠ”ë° ì´ ë•Œ ë‘ê°€ì§€ ë¬¸ì œì ì´ ìˆë‹¤.
íŒŒë¼ë¯¸í„° ìˆ˜ì˜ ì¦ê°€
íŒŒë¼ë¯¸í„°ê°€ ëŠ˜ì–´ë‚  ê²½ìš°, ì´ì— ë¹„í•˜ì—¬ í•™ìŠµë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ ì˜¤ë²„í”¼íŒ…ì— ì¼ì–´ë‚˜ê¸° ì‰½ë‹¤.
ì»´í“¨íŒ… ìì› ì‚¬ìš©ëŸ‰ì˜ ì¦ê°€
ë§Œì•½, ë‘ê°œì˜ conv layerê°€ ì—°ì†ìœ¼ë¡œ ìˆëŠ” ìƒí™©ì—ì„œ, ê±°ì˜ ëŒ€ë¶€ë¶„ì˜ ê°€ì¤‘ì¹˜ê°€ 0ì´ë©´, ê³„ì‚°ì— ìˆì–´ì„œ ë²„ë ¤ì§€ëŠ” ìì›ì´ ë§ì•„ì§„ë‹¤.
but, ì»´í“¨íŒ…ìì›ì€ í•œì •ì ì´ë¯€ë¡œ íš¨ìœ¨ì ìœ¼ë¡œ ë¶„ë°°í•˜ëŠ” ê²ƒì´ ì¤‘ìš”</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dobe0715.github.io/posts/classifier-free-diffusion-guidance/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/classifier-free-diffusion-guidance/</guid>
      <description>Classifier-free Diffusion Guidance(2022) (ì°¸ê³ ë§í¬)
youtube : https://www.youtube.com/watch?v=Q_o0SpXv9kU blog : https://kimjy99.github.io/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/cfdg/ paper : https://arxiv.org/abs/2207.12598 Contributions unconditional modelì„ í•™ìŠµí•˜ë©´ì„œ ë™ì‹œì— conditional modelì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆë‹¤. ê¸°ì¡´ì— ë¹„í•´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ê°„ë‹¨í™” í•˜ì˜€ë‹¤, BackGround Diffusion Models Beat GANs on Image Synthesis(Classifier Guidance ì œì•ˆ) í•µì‹¬ì€, conditional ëª¨ë¸ì˜ likelihood ì‹ì„ ì˜ ì „ê°œí•˜ë©´, unconditional ëª¨ë¸ê³¼ classifier ëª¨ë¸ë¡œ ë‚˜ëˆ  í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤.
$p_{\theta, \phi}(x_t|x_{t+1}, y) \simeq Zp_{\theta}(x_t|x_{t+1})p_{\phi}(y|x_t) \simeq \log{p_\theta(z)} + C_4, z \sim N(\mu_\phi + \Sigma_\phi g, \Sigma_\phi)$</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dobe0715.github.io/posts/ddpm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/ddpm/</guid>
      <description>Denoising Diffusion Probabilistic Models ì°¸ê³  ë§í¬
Diffusion Model ìˆ˜í•™ì´ í¬í•¨ëœ tutorial : https://www.youtube.com/watch?v=uFoGaIVHfoE learn open cvì—ì„œ ì˜¬ë¦° í¬ìŠ¤íŠ¸ : https://learnopencv.com/denoising-diffusion-probabilistic-models/ Paper
https://arxiv.org/pdf/2006.11239.pdf ë…¼ë¬¸ì—ì„œì˜ ì•„ì´ë””ì–´ ë°ì´í„°ì— ë§¤ìš° ì‘ì€ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ëŠ” processë¥¼ ì¤‘ì²©í•´ì„œ í•´ì£¼ë©´ normal distribution ê¹Œì§€ ë³´ë‚¼ ìˆ˜ ìˆë‹¤. ê·¸ë¦¬ê³  ì´ê²ƒì„ ë§ˆì°¬ê°€ì§€ë¡œ ìˆœì°¨ì ìœ¼ë¡œ denoising í•´ì¤˜ ì´ë¯¸ì§€ë¥¼ ë³µì›í•  ìˆ˜ ìˆë‹¤. í•´ì•¼í•  ê²ƒ forward : noiseì˜ ì¤‘ì²©ì„ ì–´ë–»ê²Œ í‘œí˜„í•  ê²ƒì¸ì§€? backward : noisingê³¼ì •ì„ ì–´ë–»ê²Œ íŒŒë¼ë¯¸í„°í™” í•´ì„œ lossë¥¼ êµ¬í•˜ê³  backpropaí•  ê²ƒì¸ê°€? ì–´ë–»ê²Œ? markov chainì„ ê°€ì •í•˜ì—¬ noiseì˜ ì¤‘ì²©ì„ ì„¤ëª…</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dobe0715.github.io/posts/more-diffusion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/more-diffusion/</guid>
      <description>ì°¸ê³ ìë£Œ blogs
(lil log, what are Diffusion Models?) : https://lilianweng.github.io/posts/2021-07-11-diffusion-models/ (Yang song, Generative Modeling by Estimating gradients of the data distribution) : https://yang-song.net/blog/2021/score/ í•œêµ­ ë¸”ë¡œê·¸ : https://deepseow.tistory.com/61 improved DDPM notion : https://sang-yun-lee.notion.site/Improved-Denoising-Diffusion-Probabilistic-Models-efa847335aef4163bfd3ee96c176f659 Diffusion models beats GANs : https://sang-yun-lee.notion.site/Diffusion-Models-Beat-GANs-on-Image-Synthesis-eb1f3826618d42e89d92e489c39f1371 papers
(Improved Denoising Diffusion Probablistic Models) : https://arxiv.org/pdf/2102.09672.pdf (Diffusion models beats GANs on Image synthesis) : https://arxiv.org/pdf/2105.05233.pdf youtubes
(improved DDPM) : https://www.youtube.com/watch?v=8dchQOqvrCE (Diffusion models beats GANs) : https://www.youtube.com/watch?v=bSqA2AIaHy8&amp;amp;t=327s Improved DDPM (contribution)
reverseí•  ë•Œ variance termë„ ì–´ëŠì •ë„ í•™ìŠµ í•˜ê²Œ í•´ì„œ NLL(negative log-likelihood)ê°’ì„ ë‚®ì¶”ì—ˆë‹¤.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dobe0715.github.io/posts/neural-ode/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/neural-ode/</guid>
      <description>Neural Ordinary Differential Equations ì°¸ê³ ìë£Œ
paper : https://arxiv.org/abs/1806.07366 blog : https://seewoo5.tistory.com/12 youtube : https://www.youtube.com/watch?v=UegW1cIRee4&amp;amp;t=1594s Contributions íŠ¹ë³„í•œ backpropagationì„ ì‚¬ìš©í•´ Memoryì˜ ì ˆì•½ì„ ì´ë¤˜ë‹¤. ê¸°ì¡´ì˜ ë°˜ë³µì ì¸ networkë“¤ì„ ì¼ë°˜í™”í•˜ì—¬ í•´ì„í•  ìˆ˜ ìˆë‹¤. forward method ResNetì˜ ê²½ìš°ë¥¼ ì‚´í´ë³´ë©´, residual connectionì´ ë°˜ë³µë˜ëŠ” êµ¬ì¡°ë¼ê³  ìƒê° í•  ìˆ˜ ìˆë‹¤.
ì´ ë•Œ, hidden stateê°€ ë‹¤ìŒê³¼ ê°™ì´ residual blockì„ ê±°ì¹˜ëŠ” ê³¼ì •ì„ ì¬ê·€ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.
$h_{t+1} = h_t + f(h_t, \theta_t)$
ì´ë¥¼ í’€ì–´ì„œ ì“°ë©´, Të²ˆì§¸ stateëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. $h_T = h_0 + f(h_0, \theta_0) + f(h_1, \theta_1) + &amp;hellip; + f(h_{T-1}, \theta_{T-1})$</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dobe0715.github.io/posts/pix2pix-zero/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/pix2pix-zero/</guid>
      <description>Review : Zero-shot Image-to-Image Translation(pix2pix zero) pre-trainëœ ëª¨ë¸ë§Œìœ¼ë¡œ pix2pix ì‘ì—…ì„ ì™„ì„±ë„ ìˆê²Œ ìˆ˜í–‰í•œ ëª¨ë¸ 1. í•µì‹¬ë‚´ìš© traing free, prompt free input text prompting ì—†ì´ ìë™ìœ¼ë¡œ direction editing cross-attention guidanceë¥¼ í†µí•´ content ë³´ì¡´ auto correlation regularization conditional GAN distillation 2. Related Works Deep image editing with GANs ê¸°ì¡´ì˜ ì—°êµ¬ë“¤ì€ target imgaeì˜ latent vectorë¥¼ disentangleí•œ spaceë¡œ ë³´ëƒ„ìœ¼ë¡œì¨, latent vectorë¥¼ ì¡°ì‘í•˜ì—¬ image translationì„ ìˆ˜í–‰í•˜ì˜€ë‹¤. ex) styleganì—ì„œì˜ W space single categoryì— ëŒ€í•´ íš¨ê³¼ì , high quality inversion ë‹¨ì ì€ image setì„ ë‚´ê°€ ì˜ ì‚¬ì „ì— ì¤€ë¹„í•´ë†”ì•¼í•œë‹¤&amp;hellip; pre trained GANì´ìš©!</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dobe0715.github.io/posts/score-based-model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/score-based-model/</guid>
      <description>Score Based Model (Reference)
2011(denoising score matching) https://www.iro.umontreal.ca/~vincentp/Publications/smdae_techreport.pdf 2019(score based generative model) https://arxiv.org/pdf/1907.05600.pdf 2021(score based SDE model) https://arxiv.org/pdf/2011.13456.pdf 2021(SDEdit) https://arxiv.org/pdf/2108.01073.pdf (youtube)
(VAE ê°•ì˜) https://www.youtube.com/watch?v=o_peo6U7IRM (ì‹œë¦½ëŒ€ ê°•ì˜) https://www.youtube.com/watch?v=HjriJyr8VZ8&amp;amp;list=PLeiav_J6JcY8iFItzNZ_6PMlz9W4_jz5J&amp;amp;index=57 (diffusion ê°•ì˜) https://www.youtube.com/watch?v=uFoGaIVHfoE Goal of Generative Model ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” ë°ì´í„°ë“¤ì˜ ì‹¤ì œ ë¶„í¬ $p(x)$ê°€ ì¡´ì¬í•œë‹¤ê³  ê°€ì •. ì´ë¥¼ ë°ì´í„°ë“¤ì„ ê°€ì§€ê³ , $p(x)$ì™€ $g_{\theta}(x)$ê°€ ìœ ì‚¬í•´ì§€ë„ë¡ íŒŒë¼ë¯¸í„° $\theta$ë¥¼ í•™ìŠµì‹œí‚¨ë‹¤. ì´í›„, ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìƒì„±í•œë‹¤ëŠ” ê²ƒì€ í•™ìŠµí•œ $g_{\theta}$ì— $x_0$ë¥¼ ëŒ€ì…í•˜ì—¬ $g_{\theta}(x_0)$ ë¼ëŠ” ê²°ê³¼ë¬¼ì„ samplingí•˜ëŠ” ê²ƒì´ë‹¤. ì´ë•Œ, $p(x)$ì˜ ë¶„í¬ë¥¼ ëª¨ë¥¼ ë•Œ(Implicit), ì•Œ ë•Œ(Explicit)ì˜ ê²½ìš° íŒŒë¼ë¯¸í„°ì˜ í•™ìŠµë°©ë²•ì´ ë‹¬ë¼ì§„ë‹¤.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dobe0715.github.io/posts/sdedit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/sdedit/</guid>
      <description>import sys sys.version &#39;3.10.11 (main, Apr 5 2023, 14:15:10) [GCC 9.4.0]&#39; !git clone https://github.com/ermongroup/SDEdit.git %cd /content/SDEdit Cloning into &#39;SDEdit&#39;... remote: Enumerating objects: 156, done.[K remote: Counting objects: 100% (155/155), done.[K remote: Compressing objects: 100% (89/89), done.[K remote: Total 156 (delta 69), reused 129 (delta 57), pack-reused 1[K Receiving objects: 100% (156/156), 37.39 MiB | 7.62 MiB/s, done. Resolving deltas: 100% (69/69), done. /content/SDEdit from google.colab import drive drive.mount(&amp;#39;/content/drive&amp;#39;) Mounted at /content/drive import numpy as np import matplotlib.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dobe0715.github.io/posts/stable-diffusion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/stable-diffusion/</guid>
      <description>High-Resolution Image Synthesis with Satent Diffusion Models(Stable Diffusion) ì°¸ê³ ìë£Œ
paper : https://arxiv.org/abs/2112.10752 youtube : https://www.youtube.com/watch?v=rC34475rEnw blog : https://kimjy99.github.io/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/ldm/ Contributions ê¸°ì¡´ì˜ DMë“¤ì— ë¹„í•´ ì†Œëª¨ë˜ëŠ” ì»´í“¨íŒ… ìì›ì„ í›¨ì”¬ ì¤„ì˜€ë‹¤. =&amp;gt; íƒ„ì†Œë°°ì¶œ ê°ì†Œ..^^ spaceì— ë”°ë¼ 2-stageë¡œ ë‚˜ëˆ  í•™ìŠµìœ¼ë¡œì¨ ë”ìš± íš¨ìœ¨ì ì¸ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ìˆì—ˆë‹¤. cross-attentionì„ U-Netì— ì ìš©í•˜ì—¬ ë‹¤ì–‘í•œ class conditionì„ ì¤„ ìˆ˜ ìˆë‹¤. ì‚¬ì „í•™ìŠµëª¨ë¸ì„ ë¬´ë£Œê³µê°œí–ˆë‹¤. ê¸°ì¡´ì˜ ì´ë¯¸ì§€ ìƒì„±ëª¨ë¸ë“¤ GAN
ì¥ì  : ì¢‹ì€ í€„ë¦¬í‹°ì˜ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ë‹¨ì  : ë°ì´í„° ë¶„í¬ ì „ì²´ í•™ìŠµì—ì„œì˜ ì–´ë ¤ì›€(mode collapse ìœ„í—˜) VAE(Likelihood-based)</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dobe0715.github.io/posts/style-transfer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/style-transfer/</guid>
      <description>Review : Image Style Transfer Using Convolutional Neural Networks ë”¥ëŸ¬ë‹ì„ ì´ìš©í•˜ì—¬ styleì„ í•©ì„±ì„ ì‹œë„í•œ ì´ˆê¸° ëª¨ë¸. 0. ë”¥ëŸ¬ë‹ ëª¨ë¸ ì‚¬ì „ì— í•™ìŠµë˜ì–´ìˆëŠ” VGG-19ë¥¼ ì‚¬ìš©. ì´ì¤‘ì—ì„œ 5ê°œì˜ convê³„ì¸µ ê°€ì ¸ì˜´. ë…¸ì´ì¦ˆ($\vec{x}$)ì™€ ì‹¤ì œ ì´ë¯¸ì§€ ì‚¬ì´ì˜ lossë¥¼ ì¤„ì—¬ ë…¸ì´ì¦ˆë¥¼ ì‹¤ì œ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ìœ¼ë¡œ ì¶”ë¡ . 1. ëª©ì í•¨ìˆ˜ ê°ê°ì˜ lossë¥¼ ì„¤ê³„í•˜ëŠ”ë°ì— ìˆì–´ì„œ CNNì˜ feature mapì˜ ì„±ì§ˆì„ ì ê·¹ í™œìš©í•˜ì˜€ë‹¤. ì¸µì´ ê¹Šì–´ì§ˆ ìˆ˜ë¡, chanelìˆ˜ëŠ” ì¦ê°€í•˜ê³ , filterí¬ê¸°ëŠ” ê°ì†Œí•œë‹¤! ì¸µì´ ê¹Šì–´ì§ˆ ìˆ˜ë¡, styleì€ ë§ì´ ë‹´ê³ , contentëŠ” ì ê²Œë‹´ëŠ”ë‹¤! contentëŠ” filterì—ì„œì˜ êµ¬ì²´ì ì¸ ê°’, styleì€ filterê°„ì˜ ë¶„í¬ë„ ê°’ì— ëŒ€ì‘ ì‹œì¼°ë‹¤.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dobe0715.github.io/posts/stylegan2-ada/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/stylegan2-ada/</guid>
      <description>Review : Training Generative Adversarial Networks with Limited Data (stylegan2-ada) ADA(Adaptive Discriminator Augmentation) í•„ìš”í•œ ë°ì´í„° ìˆ˜ì‹­, ìˆ˜ë°±ë§Œì¥ -&amp;gt; ìˆ˜ ì²œì¥ GAN ë°ì´í„° ë§ì´ í•„ìš”í•œ ì´ìœ  discriminatorê°€ ì ì€ ì–‘ì˜ ë°ì´í„° ì…‹ì— ê³¼ì í•© ë  ìˆ˜ ìˆë‹¤. (a)ë¥¼ ë³´ë©´, 14ë§Œì¥ì´ ëª¨ì—¬ì•¼ ê³¼ì í•© ë°œìƒí•˜ì§€ ì•ŠìŒì„ ë³¼ ìˆ˜ ìˆë‹¤. (b), (c)ë¥¼ ë³´ë©´, fid scoreë¡œë¶€í„° ê³„ì† ë©€ì–´ì§ì„ ì•Œ ìˆ˜ ìˆê³ , ê²€ì¦ë°ì´í„°ì™€ ìƒì„±ë°ì´í„°ëŠ” ê°€ê¹ê²Œ íŒë‹¨í•˜ëŠ” ë°˜ë©´ì—, í›ˆë ¨ë°ì´í„°ëŠ” ë°˜ëŒ€ë¡œ, ì™„ì „íˆ ê³¼ì í•© ìƒíƒœì— ê°€ê¹Œì›Œì§„ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë¬´ë ¤ 2ë§Œ, 5ë§Œì¸ë°ë„.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dobe0715.github.io/posts/vae/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/vae/</guid>
      <description>VAE (ì†¡ê²½ìš°êµìˆ˜ë‹˜ ë”¥ëŸ¬ë‹ê°•ì˜ 2022) https://www.youtube.com/watch?v=V-lWbJtNzTc&amp;amp;list=PLeiav_J6JcY8iFItzNZ_6PMlz9W4_jz5J&amp;amp;index=58
Generative model MLEì˜ ê´€ì ì—ì„œ ë³´ì•˜ì„ ë•Œ, $p_\theta(x)$ë¥¼ ìµœëŒ€í™” í•˜ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ëŠ” ê²ƒì´ë‹¤! ê²°êµ­ ëª©ì í•¨ìˆ˜ëŠ”,
$$\theta^* = \arg\max\limits_{\theta}\cfrac{1}{N}\sum_{i=1}^N\log{p_\theta(x_i)}$$
ì´ë‹¤.
Variational Inference ì–´ë–¤ ì¡°ê±´ì´ ì£¼ì–´ì¡Œì„ ë•Œì˜ í™•ë¥ ($p(z|x)$)ì„ ë‹¤ë£¨ê¸° ì‰¬ìš´ í™•ë¥ ë¶„í¬($q(z)$)ë¡œ ê·¼ì‚¬í•˜ëŠ” ê²ƒ. ì¦‰, log-likelihood($\log{p(x_i)}$)ì˜ lower boundì¸ $L$ë¥¼ maximizeí•˜ë©´ ê²°êµ­ì— $q_i(z)$ê°€ $p(z|x_i)$ì™€ ê°€ê¹Œì›Œì ¸, ì‹¤ì œ ìƒ˜í”Œì— ëŒ€ì‘í•˜ëŠ” latentë¥¼ ë” ì˜ ë½‘ì•„ì¤„ ìˆ˜ ìˆê²Œ ëœë‹¤.
ì´ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•´ elboë¥¼ maximize í•˜ëŠ” ê³¼ì •ì„ ì‚´í´ë³´ë©´,
ië²ˆì§¸ ìƒ˜í”Œ ë°ì´í„°í•™ìŠµí•  ë•Œ ë§ˆë‹¤, $q_i$ë¡œë¶€í„° $\mu_i, \Sigma_i$ë¥¼ ì–»ì–´ë‚´ê³ , ì—¬ê¸°ë¡œë¶€í„°ì˜ ë¶„í¬ì—ì„œ ë‹¤ì‹œ $\hat{x}$ë¥¼ ë½‘ì•„ë‚´ì„œ($\theta$), $x_i$ì™€ ë‹®ë„ë¡ í•™ìŠµí•œë‹¤.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dobe0715.github.io/posts/variational-diffusion-models/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/variational-diffusion-models/</guid>
      <description>Variational Diffusion Models(2021) ì°¸ê³ ë§í¬
ìœ íŠœë¸Œ : https://www.youtube.com/watch?v=yR81b3UxgaI&amp;amp;t=1354s ë…¸ì…˜ : https://sang-yun-lee.notion.site/Variational-Diffusion-Models-f72d9cb1a2004a9088470c95cdc929e3 ë…¼ë¬¸ : https://arxiv.org/abs/2107.00630 Contributions likelihood SOTA ì°ì—ˆë‹¤. ëª¨ë¸ íŒŒë¼ë¯¸í„°($w$)ì™€ ë™ì‹œì— noise schadule($\gamma$)ë„ í•™ìŠµì‹œì¼°ë‹¤. VLBë¥¼ SNRë¥¼ í†µí•´ ê°„ë‹¨íˆ í‘œí˜„í•˜ì˜€ë‹¤. continuous-time VLBê°’ì€ noise scheduleê³¼ ê´€ë ¨ì—†ìŒì„ ë³´ì˜€ë‹¤.(ê° ëì ê³¼ ê´€ë ¨ìˆìŒ) Model 1. Forward time diffusion process $x$ : ì£¼ì–´ì§„ ë°ì´í„° $p(x)$ : ì¸¡ì •ëœ xì˜ ì£¼ë³€ë¶„í¬ $z_t$ : $t$ ì‹œê°„ì—ì„œì˜ latent variable 0. definitions $q(z_t|x) = N(\alpha_t x, \sigma_t^2 I)$ $SNR(t) = \cfrac{\alpha_t^2}{\sigma_t^2}$ ì´ ë•Œ, SNRì€ ë‹¨ì¡° ê°ì†Œë¥¼ ë§Œì¡±ì‹œì¼œì•¼ í•œë‹¤.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dobe0715.github.io/posts/wgan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/wgan/</guid>
      <description>Review : Wasserstein GAN ìƒˆë¡œìš´ metricì„ í†µí•œ GANì˜ lossë¥¼ ì œì‹œ. ë¶„ë¥˜ëª¨ë¸ê°™ì€ê²½ìš°ëŠ” ì •ë‹µì´ í™•ì‹¤íˆ ì •í•´ì ¸ìˆì–´ì„œ ëª¨ë¸ì˜ lossë¥¼ í™•ì‹¤íˆ ì •ëŸ‰í™” í•  ìˆ˜ ìˆì—ˆë‹¤.(cross-entropy, mse ë“±) í•˜ì§€ë§Œ ìƒì„±ëª¨ë¸ì€ ì–´ëŠì •ë„ê°€ ì •ë‹µê³¼ ê°€ê¹Œìš´ì§€ ì •ëŸ‰ì ìœ¼ë¡œ ì¸¡ì •í•˜ê¸° í˜ë“¤ë‹¤. ì´ëŸ¬í•œ ê²ƒì„ í•´ê²°í•˜ê¸° ìœ„í•œ metricì´ë‹¤. 4ê°€ì§€ ê±°ë¦¬ê°œë… ì£¼ì–´ì§„ ê°€ì • $\mathcal{X}$ : compact metric(ìœ ê³„ì¸ ë‹«íŒ ê³µê°„) $\Sigma$ : $\mathcal{X}$ì˜ Borel subsetë“¤ì˜ ì§‘í•© (ì¸¡ì •ê°€ëŠ¥í•œ ì§‘í•©ì— ëŒ€í•´ì„œë§Œ í™•ë¥ ì„ ë…¼í•˜ê² ë‹¤) $Prob(\mathcal{X})$ : $\mathcal{X}$ì˜ í™•ë¥ ì¸¡ë„ê³µê°„ ë‘ ë¶„í¬ $\mathbb{P}_r, \mathbb{P}_g \in Prob(\mathcal{X})$ì— ëŒ€í•˜ì—¬&amp;hellip;
1. TV(Total Variation) distance $$\delta(\mathbb{P}_r, \mathbb{P}g) = \sup{A \in \Sigma}|\mathbb{P}_r(A)- \mathbb{P}_g(A)|$$</description>
    </item>
    
    <item>
      <title>ConvNeXt review</title>
      <link>https://dobe0715.github.io/posts/convnext/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/convnext/</guid>
      <description>A ConvNet for the 2020s ì°¸ê³ ë§í¬
https://arxiv.org/abs/2201.03545 https://americanoisice.tistory.com/121 ë…¼ë¬¸ì˜ ì•„ì´ë””ì–´ ê¸°ì¡´ì— computer visionì—ì„œëŠ” &amp;ldquo;sliding window&amp;quot;ê¸°ë²•ì´ ì£¼ëœë°©ë²•ì´ì—ˆë‹¤. ë°˜ë©´ì— NLPë¶„ì•¼ì—ì„œëŠ” transformerë¼ëŠ” ì—„ì²­ë‚œ ëª¨ë¸ì´ ë‚˜ì™”ê³ , ì´ë¥¼ CVì™€ ê²°í•©í•˜ì—¬ ViTë¼ëŠ” ëª¨ë¸ì´ ë‚˜ì˜¤ë©´ì„œ, ì´ ì—­ì‹œ SOTAë¥¼ ë°¥ë¨¹ë“¯ì´ í•˜ê³ ìˆë‹¤..
Transformerì—ì„œ ì‚¬ìš©í•œ ê¸°ìˆ ë“¤ì„ ConvNetì— ì ìš©í•œë‹¤ë©´ ì–´ë–»ê²Œ ë ê¹Œ?
ì´ ë•Œ, ResNetë§Œ ê°€ì§€ê³  ë°œì „ì‹œí‚¨ë‹¤.
ConvNetì˜ Modernizing ResNet-50/200 vs Swin-T/Bìœ¼ë¡œ ëª¨ë¸ì„ ëŒ€ì‘ì‹œì¼œ ê°ê° FLOPsë¥¼ ë§ì¶°ì„œ ë¹„êµí•œë‹¤.
macro design 2) ResNeXt 3) inverted bottleneck 4) large kernel size 5) various layer-wise micro design 1.</description>
    </item>
    
  </channel>
</rss>

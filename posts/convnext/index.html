<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>ExampleSite</title><meta name=keywords content><meta name=description content="A ConvNet for the 2020s 참고링크
https://arxiv.org/abs/2201.03545 https://americanoisice.tistory.com/121 논문의 아이디어 기존에 computer vision에서는 &ldquo;sliding window&#34;기법이 주된방법이었다. 반면에 NLP분야에서는 transformer라는 엄청난 모델이 나왔고, 이를 CV와 결합하여 ViT라는 모델이 나오면서, 이 역시 SOTA를 밥먹듯이 하고있다..
Transformer에서 사용한 기술들을 ConvNet에 적용한다면 어떻게 될까?
이 때, ResNet만 가지고 발전시킨다.
ConvNet의 Modernizing ResNet-50/200 vs Swin-T/B으로 모델을 대응시켜 각각 FLOPs를 맞춰서 비교한다.
macro design 2) ResNeXt 3) inverted bottleneck 4) large kernel size 5) various layer-wise micro design 1."><meta name=author content="Me"><link rel=canonical href=https://dobe0715.github.io/posts/convnext/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content><meta property="og:description" content="A ConvNet for the 2020s 참고링크
https://arxiv.org/abs/2201.03545 https://americanoisice.tistory.com/121 논문의 아이디어 기존에 computer vision에서는 &ldquo;sliding window&#34;기법이 주된방법이었다. 반면에 NLP분야에서는 transformer라는 엄청난 모델이 나왔고, 이를 CV와 결합하여 ViT라는 모델이 나오면서, 이 역시 SOTA를 밥먹듯이 하고있다..
Transformer에서 사용한 기술들을 ConvNet에 적용한다면 어떻게 될까?
이 때, ResNet만 가지고 발전시킨다.
ConvNet의 Modernizing ResNet-50/200 vs Swin-T/B으로 모델을 대응시켜 각각 FLOPs를 맞춰서 비교한다.
macro design 2) ResNeXt 3) inverted bottleneck 4) large kernel size 5) various layer-wise micro design 1."><meta property="og:type" content="article"><meta property="og:url" content="https://dobe0715.github.io/posts/convnext/"><meta property="og:image" content="https://dobe0715.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dobe0715.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content><meta name=twitter:description content="A ConvNet for the 2020s 참고링크
https://arxiv.org/abs/2201.03545 https://americanoisice.tistory.com/121 논문의 아이디어 기존에 computer vision에서는 &ldquo;sliding window&#34;기법이 주된방법이었다. 반면에 NLP분야에서는 transformer라는 엄청난 모델이 나왔고, 이를 CV와 결합하여 ViT라는 모델이 나오면서, 이 역시 SOTA를 밥먹듯이 하고있다..
Transformer에서 사용한 기술들을 ConvNet에 적용한다면 어떻게 될까?
이 때, ResNet만 가지고 발전시킨다.
ConvNet의 Modernizing ResNet-50/200 vs Swin-T/B으로 모델을 대응시켜 각각 FLOPs를 맞춰서 비교한다.
macro design 2) ResNeXt 3) inverted bottleneck 4) large kernel size 5) various layer-wise micro design 1."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://dobe0715.github.io/posts/"},{"@type":"ListItem","position":3,"name":"","item":"https://dobe0715.github.io/posts/convnext/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"","name":"","description":"A ConvNet for the 2020s 참고링크\nhttps://arxiv.org/abs/2201.03545 https://americanoisice.tistory.com/121 논문의 아이디어 기존에 computer vision에서는 \u0026ldquo;sliding window\u0026quot;기법이 주된방법이었다. 반면에 NLP분야에서는 transformer라는 엄청난 모델이 나왔고, 이를 CV와 결합하여 ViT라는 모델이 나오면서, 이 역시 SOTA를 밥먹듯이 하고있다..\nTransformer에서 사용한 기술들을 ConvNet에 적용한다면 어떻게 될까?\n이 때, ResNet만 가지고 발전시킨다.\nConvNet의 Modernizing ResNet-50/200 vs Swin-T/B으로 모델을 대응시켜 각각 FLOPs를 맞춰서 비교한다.\nmacro design 2) ResNeXt 3) inverted bottleneck 4) large kernel size 5) various layer-wise micro design 1.","keywords":[],"articleBody":"A ConvNet for the 2020s 참고링크\nhttps://arxiv.org/abs/2201.03545 https://americanoisice.tistory.com/121 논문의 아이디어 기존에 computer vision에서는 “sliding window\"기법이 주된방법이었다. 반면에 NLP분야에서는 transformer라는 엄청난 모델이 나왔고, 이를 CV와 결합하여 ViT라는 모델이 나오면서, 이 역시 SOTA를 밥먹듯이 하고있다..\nTransformer에서 사용한 기술들을 ConvNet에 적용한다면 어떻게 될까?\n이 때, ResNet만 가지고 발전시킨다.\nConvNet의 Modernizing ResNet-50/200 vs Swin-T/B으로 모델을 대응시켜 각각 FLOPs를 맞춰서 비교한다.\nmacro design 2) ResNeXt 3) inverted bottleneck 4) large kernel size 5) various layer-wise micro design 1. Training techniques DeiTm, Swin Transformer에서 사용한 훈련 법을 가져왔다.\nepochs 90 -\u003e 300 AdamW optimizer data augmentation(Mixup, Cutmix, RandAugment, RandomDrasing) Stochastic Depth layer를 무작위로 drop해준다.(Drop out의 layer 버전이라고 볼 수 있음. test때에는 dropout과 마찬가지로 1-p곱해주는 형식) Label Smoothing 얘네들 사용해서 76.1% -\u003e 78.8%(+2.7%)의 상승효과 얻었다.\n2. Macro Design Cell 단위의 조정이다.\ncompute ratio 수정\n기존의 ResNet은 각 stage마다 3:4:6:3번의 연산을 반복했다.\nbut, swin transformer에서는 가장 작은건 1:1:3:1, 그 이후는 1:1:9:1 비율의 ratio로 연산을 반복하였다.\n그래서 마찬가지의 형태를 적용. 78.8% -\u003e 79.4% 상승\nStem cell을 Patchify하게 바꾸기\n기존 ResNet은 7x7(2), max pool(2)를 통해 input image를 4배 downsampling하였다.\n이에 반해, ViT에서는 patch단위 14 혹은 16를 기준으로하였는데, 이는 non-overlapping conv를 사용했다고 볼 수 있다. 따라서, 4x4(4)를 사용하였다.\n79.4% -\u003e 79.5% 상승\nResNeXt-ify ResNext에서 사용한 grouped conv의 개념을 이용한다.\n실제로, ResNeXt에서는 conv block을 group conv로 바꾸는 대신, 그만큼 channel 수를 늘려서 bottle neck을 완화하고 같은 parameter수 대비 성능을 끌어올렸다.\n이 때, 특별하게 group수와 앞의 feature map channel수가 동일하다면, 각 channel마다 담당하는 conv block이 생기게 되는데 이는 정확히 depthwise convolution과 동일하다.(Mobile Net)\n해당 논문에서는 이러한 depthwise convolution이 self-attention에서의 weighted sum operation과 유사하다고 이야기한다.\n어쨌든, 이렇게 depthwise conv이후에 1x1 conv를 통해 channel mixing까지 적용한 모델을 사용하였다. 그리고, Swin-T에서의 channel수와 동일하게 96을 적용하였으며\n그 결과 80.5%의 퍼포먼스를 보였다.\n4. Inverted Bottleneck (a)가 기존의 ResNeXt에서 사용한 구조이다. 우리는 depthwise seperable block을 사용하기 때문에,\n중간의 bottle neck(3x3 conv연산 하는 구간)을 오히려 크게 키워도 연산량을 커버할 수 있게 된다.\n따라서, (b)가 바꾼 형태이고, (c)와 같이 앞으로 옮겨서도 실험해봤는데(Transformer의 MSA block모양을 따라하기 위해) 성능이 하락하는 모습을 보였다..\n(b)를 적용했을 때,\n80.5% -\u003e 80.6%(Res-200에 적용하면 81.9% -\u003e 82.6%)\n5. Large Kernel Sizes depthwise conv layer 이동 ViT 모델의 MSA block과 형태를 동일하게 하기 위해서 conv 블럭을 앞으로 뺐다.(MSA는 self-attention 이후 mlp) 즉, (c)와 같은 형태처럼 conv 이후 1x1연산 함으로써 mlp 보낸 효과.\nbut, 성능은 79.9%으로 하락하였다.\nkernel size 증가\nViT모델의 경우, non-local self-attention을 적용하기 때문에,(patch단위로 전체 attention) global한 receptive field를 가진다. 이것이 성능에 중요한 영향이라고 생각하여, conv size늘려보겠다.\n이 대, 3, 5, 7, 9, 11에 대해 FLOPs를 고정시키고 바꾸어 봤는데, 7일 때 가장 좋았다.\n성능은 79.9% -\u003e 80.6%으로 향상되었다.\nThink\n그러면 depthwise 이동안시키고 kernel size증가는 안시켜봤나??\n6. Micro Design activation, normalization을 어떤걸 사용할지 선택\nReLU -\u003e GELU\n최근의 많은 연구에서 ReLU대신에 GELU를 사용했을 때, 좋은 효과를 봤다. 그래서 마찬가지로 GELU로 바꿔봤다.\n80.6% 동일.\nactivation 줄이기\nTransformer의 경우, MLP사이에 GELU 하나 뿐이다.\n마찬가지로, 1x1 블럭 사이에 GELU만 추가한다.(이것 때문에 위에서 depthwise 이동시킨 것 같다.)\nBN -\u003e LN\nBatch normalization은 모델에 있어서 꽤나 복잡한 악영향을 끼치기도 한다.(주로 데이터 상의 문제)\n따라서, transformer의 경우 LN을 사용해왔는데, 여기에서도 BN을 LN으로 바꿔보았다. 7x7 conv 직후에 넣었다.\naccuracy 81.5%으로 사응하였다.\ndownsampling layer를 분리해보기(block으로부터)\nResnet의 경우, 3x3(2)를 적용한 후 shortcut connection을 진행할 때, 1x1(2) 적용해놓고 합쳤다.(정보의 손실발생..)\n하지만, Swin-T의 경우, 각 stage사이에 downsampling을 적용하였다.\n마찬가지로, 우리의 모델은 2x2(2) 를 각 block사이에 넣어준다.\n이를 마지막으로 모델이 확정되어 LN이 들어가는 부분이 정해진다. 각 downsampling layer 이전 / stem 이후 / GAP이후 accuracy 82.0%를 달성하였다.(Swin-T : 81.3%)\n기존 ViT모델 에 대해 비슷한 param, 연산량 대비 정확도가 더 높고 처리속도가 빠르다.\n","wordCount":"561","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://dobe0715.github.io/posts/convnext/"},"publisher":{"@type":"Organization","name":"ExampleSite","logo":{"@type":"ImageObject","url":"https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dobe0715.github.io accesskey=h title="Home (Alt + H)"><img src=https://dobe0715.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://dobe0715.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://dobe0715.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://example.org title=example.org><span>example.org</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dobe0715.github.io>Home</a>&nbsp;»&nbsp;<a href=https://dobe0715.github.io/posts/>Posts</a></div><h1 class=post-title></h1><div class=post-meta>3 min&nbsp;·&nbsp;561 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/ConvNeXt.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><h1 id=a-convnet-for-the-2020s>A ConvNet for the 2020s<a hidden class=anchor aria-hidden=true href=#a-convnet-for-the-2020s>#</a></h1><p>참고링크</p><ul><li><a href=https://arxiv.org/abs/2201.03545>https://arxiv.org/abs/2201.03545</a></li><li><a href=https://americanoisice.tistory.com/121>https://americanoisice.tistory.com/121</a></li></ul><h2 id=논문의-아이디어>논문의 아이디어<a hidden class=anchor aria-hidden=true href=#논문의-아이디어>#</a></h2><p>기존에 computer vision에서는 &ldquo;sliding window"기법이 주된방법이었다.
반면에 NLP분야에서는 transformer라는 엄청난 모델이 나왔고, 이를 CV와 결합하여 ViT라는 모델이 나오면서, 이 역시 SOTA를 밥먹듯이 하고있다..<br><strong>Transformer에서 사용한 기술들을 ConvNet에 적용한다면 어떻게 될까?</strong></p><p>이 때, ResNet만 가지고 발전시킨다.</p><h2 id=convnet의-modernizing>ConvNet의 Modernizing<a hidden class=anchor aria-hidden=true href=#convnet의-modernizing>#</a></h2><p>ResNet-50/200 vs Swin-T/B으로 모델을 대응시켜 각각 FLOPs를 맞춰서 비교한다.</p><ol><li>macro design 2) ResNeXt 3) inverted bottleneck 4) large kernel size 5) various layer-wise micro design</li></ol><h3 id=1-training-techniques>1. Training techniques<a hidden class=anchor aria-hidden=true href=#1-training-techniques>#</a></h3><p>DeiTm, Swin Transformer에서 사용한 훈련 법을 가져왔다.</p><ul><li>epochs 90 -> 300</li><li>AdamW optimizer</li><li>data augmentation(Mixup, Cutmix, RandAugment, RandomDrasing)</li><li>Stochastic Depth<ul><li>layer를 무작위로 drop해준다.(Drop out의 layer 버전이라고 볼 수 있음. test때에는 dropout과 마찬가지로 1-p곱해주는 형식)</li></ul></li><li>Label Smoothing</li></ul><p>얘네들 사용해서 76.1% -> 78.8%(+2.7%)의 상승효과 얻었다.</p><h3 id=2-macro-design>2. Macro Design<a hidden class=anchor aria-hidden=true href=#2-macro-design>#</a></h3><p>Cell 단위의 조정이다.</p><ul><li><p><strong>compute ratio 수정</strong><br>기존의 ResNet은 각 stage마다 3:4:6:3번의 연산을 반복했다.<br>but, swin transformer에서는 가장 작은건 1:1:3:1, 그 이후는 1:1:9:1 비율의 ratio로 연산을 반복하였다.<br>그래서 마찬가지의 형태를 적용.
78.8% -> 79.4% 상승</p></li><li><p><strong>Stem cell을 Patchify하게 바꾸기</strong><br>기존 ResNet은 7x7(2), max pool(2)를 통해 input image를 4배 downsampling하였다.<br>이에 반해, ViT에서는 patch단위 14 혹은 16를 기준으로하였는데, 이는 non-overlapping conv를 사용했다고 볼 수 있다.<br>따라서, 4x4(4)를 사용하였다.<br>79.4% -> 79.5% 상승</p></li></ul><h3 id=resnext-ify>ResNeXt-ify<a hidden class=anchor aria-hidden=true href=#resnext-ify>#</a></h3><p>ResNext에서 사용한 grouped conv의 개념을 이용한다.</p><p>실제로, ResNeXt에서는 conv block을 group conv로 바꾸는 대신, 그만큼 channel 수를 늘려서 bottle neck을 완화하고 같은 parameter수 대비 성능을 끌어올렸다.</p><p>이 때, 특별하게 group수와 앞의 feature map channel수가 동일하다면, 각 channel마다 담당하는 conv block이 생기게 되는데 이는 정확히 depthwise convolution과 동일하다.(Mobile Net)<br></p><p>해당 논문에서는 이러한 depthwise convolution이 self-attention에서의 weighted sum operation과 유사하다고 이야기한다.</p><p>어쨌든, 이렇게 depthwise conv이후에 1x1 conv를 통해 channel mixing까지 적용한 모델을 사용하였다. 그리고, Swin-T에서의 channel수와 동일하게 96을 적용하였으며<br>그 결과 80.5%의 퍼포먼스를 보였다.</p><h3 id=4-inverted-bottleneck>4. Inverted Bottleneck<a hidden class=anchor aria-hidden=true href=#4-inverted-bottleneck>#</a></h3><p>(a)가 기존의 ResNeXt에서 사용한 구조이다. 우리는 depthwise seperable block을 사용하기 때문에,<br>중간의 bottle neck(3x3 conv연산 하는 구간)을 오히려 크게 키워도 연산량을 커버할 수 있게 된다.<br>따라서, (b)가 바꾼 형태이고, (c)와 같이 앞으로 옮겨서도 실험해봤는데(Transformer의 MSA block모양을 따라하기 위해) 성능이 하락하는 모습을 보였다..<br>(b)를 적용했을 때,<br>80.5% -> 80.6%(Res-200에 적용하면 81.9% -> 82.6%)</p><h3 id=5-large-kernel-sizes>5. Large Kernel Sizes<a hidden class=anchor aria-hidden=true href=#5-large-kernel-sizes>#</a></h3><ul><li><p>depthwise conv layer 이동
ViT 모델의 MSA block과 형태를 동일하게 하기 위해서 conv 블럭을 앞으로 뺐다.(MSA는 self-attention 이후 mlp)
즉, (c)와 같은 형태처럼 conv 이후 1x1연산 함으로써 mlp 보낸 효과.<br>but, 성능은 79.9%으로 하락하였다.</p></li><li><p>kernel size 증가<br>ViT모델의 경우, non-local self-attention을 적용하기 때문에,(patch단위로 전체 attention) global한 receptive field를 가진다. 이것이 성능에 중요한 영향이라고 생각하여, conv size늘려보겠다.<br>이 대, 3, 5, 7, 9, 11에 대해 FLOPs를 고정시키고 바꾸어 봤는데, 7일 때 가장 좋았다.<br>성능은 79.9% -> 80.6%으로 향상되었다.</p></li></ul><p><strong>Think</strong><br>그러면 depthwise 이동안시키고 kernel size증가는 안시켜봤나??</p><h3 id=6-micro-design>6. Micro Design<a hidden class=anchor aria-hidden=true href=#6-micro-design>#</a></h3><p>activation, normalization을 어떤걸 사용할지 선택</p><ul><li><p>ReLU -> GELU<br>최근의 많은 연구에서 ReLU대신에 GELU를 사용했을 때, 좋은 효과를 봤다. 그래서 마찬가지로 GELU로 바꿔봤다.<br>80.6% 동일.</p></li><li><p>activation 줄이기<br>Transformer의 경우, MLP사이에 GELU 하나 뿐이다.<br>마찬가지로, 1x1 블럭 사이에 GELU만 추가한다.(이것 때문에 위에서 depthwise 이동시킨 것 같다.)</p></li><li><p>BN -> LN<br>Batch normalization은 모델에 있어서 꽤나 복잡한 악영향을 끼치기도 한다.(주로 데이터 상의 문제)<br>따라서, transformer의 경우 LN을 사용해왔는데, 여기에서도 BN을 LN으로 바꿔보았다. 7x7 conv 직후에 넣었다.</p></li></ul><p>accuracy 81.5%으로 사응하였다.</p><ul><li>downsampling layer를 분리해보기(block으로부터)<br>Resnet의 경우, 3x3(2)를 적용한 후 shortcut connection을 진행할 때, 1x1(2) 적용해놓고 합쳤다.(정보의 손실발생..)<br>하지만, Swin-T의 경우, 각 stage사이에 downsampling을 적용하였다.<br>마찬가지로, 우리의 모델은 2x2(2) 를 각 block사이에 넣어준다.<br>이를 마지막으로 모델이 확정되어 LN이 들어가는 부분이 정해진다.
각 downsampling layer 이전 / stem 이후 / GAP이후</li></ul><p>accuracy 82.0%를 달성하였다.(Swin-T : 81.3%)</p><p>기존 ViT모델 에 대해 비슷한 param, 연산량 대비 정확도가 더 높고 처리속도가 빠르다.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://dobe0715.github.io/posts/hihi/><span class=title>« Prev</span><br><span>Hihi</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share  on twitter" href="https://twitter.com/intent/tweet/?text=&amp;url=https%3a%2f%2fdobe0715.github.io%2fposts%2fconvnext%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share  on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fdobe0715.github.io%2fposts%2fconvnext%2f&amp;title=&amp;summary=&amp;source=https%3a%2f%2fdobe0715.github.io%2fposts%2fconvnext%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share  on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fdobe0715.github.io%2fposts%2fconvnext%2f&title="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share  on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fdobe0715.github.io%2fposts%2fconvnext%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share  on whatsapp" href="https://api.whatsapp.com/send?text=%20-%20https%3a%2f%2fdobe0715.github.io%2fposts%2fconvnext%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share  on telegram" href="https://telegram.me/share/url?text=&amp;url=https%3a%2f%2fdobe0715.github.io%2fposts%2fconvnext%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share  on ycombinator" href="https://news.ycombinator.com/submitlink?t=&u=https%3a%2f%2fdobe0715.github.io%2fposts%2fconvnext%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://dobe0715.github.io>ExampleSite</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Image Style Transfer Using Convolutional Neural Networks review | 블로그 홈</title><meta name=keywords content><meta name=description content="Review : Image Style Transfer Using Convolutional Neural Networks 딥러닝을 이용하여 style을 합성을 시도한 초기 모델. 0. 딥러닝 모델 사전에 학습되어있는 VGG-19를 사용. 이중에서 5개의 conv계층 가져옴. 노이즈($\vec{x}$)와 실제 이미지 사이의 loss를 줄여 노이즈를 실제 이미지로 변환하는 과정으로 추론. 1. 목적함수 각각의 loss를 설계하는데에 있어서 CNN의 feature map의 성질을 적극 활용하였다. 층이 깊어질 수록, chanel수는 증가하고, filter크기는 감소한다! 층이 깊어질 수록, style은 많이 담고, content는 적게담는다! content는 filter에서의 구체적인 값, style은 filter간의 분포도 값에 대응 시켰다."><meta name=author content="Me"><link rel=canonical href=https://dobe0715.github.io/posts/style-transfer/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Image Style Transfer Using Convolutional Neural Networks review"><meta property="og:description" content="Review : Image Style Transfer Using Convolutional Neural Networks 딥러닝을 이용하여 style을 합성을 시도한 초기 모델. 0. 딥러닝 모델 사전에 학습되어있는 VGG-19를 사용. 이중에서 5개의 conv계층 가져옴. 노이즈($\vec{x}$)와 실제 이미지 사이의 loss를 줄여 노이즈를 실제 이미지로 변환하는 과정으로 추론. 1. 목적함수 각각의 loss를 설계하는데에 있어서 CNN의 feature map의 성질을 적극 활용하였다. 층이 깊어질 수록, chanel수는 증가하고, filter크기는 감소한다! 층이 깊어질 수록, style은 많이 담고, content는 적게담는다! content는 filter에서의 구체적인 값, style은 filter간의 분포도 값에 대응 시켰다."><meta property="og:type" content="article"><meta property="og:url" content="https://dobe0715.github.io/posts/style-transfer/"><meta property="og:image" content="https://dobe0715.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dobe0715.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Image Style Transfer Using Convolutional Neural Networks review"><meta name=twitter:description content="Review : Image Style Transfer Using Convolutional Neural Networks 딥러닝을 이용하여 style을 합성을 시도한 초기 모델. 0. 딥러닝 모델 사전에 학습되어있는 VGG-19를 사용. 이중에서 5개의 conv계층 가져옴. 노이즈($\vec{x}$)와 실제 이미지 사이의 loss를 줄여 노이즈를 실제 이미지로 변환하는 과정으로 추론. 1. 목적함수 각각의 loss를 설계하는데에 있어서 CNN의 feature map의 성질을 적극 활용하였다. 층이 깊어질 수록, chanel수는 증가하고, filter크기는 감소한다! 층이 깊어질 수록, style은 많이 담고, content는 적게담는다! content는 filter에서의 구체적인 값, style은 filter간의 분포도 값에 대응 시켰다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://dobe0715.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Image Style Transfer Using Convolutional Neural Networks review","item":"https://dobe0715.github.io/posts/style-transfer/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Image Style Transfer Using Convolutional Neural Networks review","name":"Image Style Transfer Using Convolutional Neural Networks review","description":"Review : Image Style Transfer Using Convolutional Neural Networks 딥러닝을 이용하여 style을 합성을 시도한 초기 모델. 0. 딥러닝 모델 사전에 학습되어있는 VGG-19를 사용. 이중에서 5개의 conv계층 가져옴. 노이즈($\\vec{x}$)와 실제 이미지 사이의 loss를 줄여 노이즈를 실제 이미지로 변환하는 과정으로 추론. 1. 목적함수 각각의 loss를 설계하는데에 있어서 CNN의 feature map의 성질을 적극 활용하였다. 층이 깊어질 수록, chanel수는 증가하고, filter크기는 감소한다! 층이 깊어질 수록, style은 많이 담고, content는 적게담는다! content는 filter에서의 구체적인 값, style은 filter간의 분포도 값에 대응 시켰다.","keywords":[],"articleBody":"Review : Image Style Transfer Using Convolutional Neural Networks 딥러닝을 이용하여 style을 합성을 시도한 초기 모델. 0. 딥러닝 모델 사전에 학습되어있는 VGG-19를 사용. 이중에서 5개의 conv계층 가져옴. 노이즈($\\vec{x}$)와 실제 이미지 사이의 loss를 줄여 노이즈를 실제 이미지로 변환하는 과정으로 추론. 1. 목적함수 각각의 loss를 설계하는데에 있어서 CNN의 feature map의 성질을 적극 활용하였다. 층이 깊어질 수록, chanel수는 증가하고, filter크기는 감소한다! 층이 깊어질 수록, style은 많이 담고, content는 적게담는다! content는 filter에서의 구체적인 값, style은 filter간의 분포도 값에 대응 시켰다.\n$F^l \\in R^{N_l \\times M_l}$\n앞으로 이 값들을 계속해서 사용한다.\n1.1 Content Loss 그림의 내용(물체의 형태, 위치)에 대한 목적함수 $$L_{content}(\\vec{p}, \\vec{x}, l) = \\cfrac{1}{2} \\sum_{i, j}({F^l_{ij} - P^l_{ij}})^2$$\np : 입력이미지, x : 노이즈 P : 입력결과값, F : 노이즈결과값 이미지 feature 위치가 같아지도록 한다고 볼 수 있다. 1.2 Style Loss 그림의 스타일에 대한 목적함수 Gram matrix $$G^l \\in R^{N_l \\times N_l}$$ $$G^l_{ij} = \\sum_k{F^l_{ik} F^l_{jk}}$$\n$l$번째 레이어의 $i$와$j$번째 feature map의 correlation을 파악하는 척도. matrix의 크기는 각 layer의 filter개수에 비례한다. 즉, 층이 깊어질 수록 Gram matrix의 크기가 커진다. Loss function $$E_l = \\cfrac{1}{4N^2_l M^2_l}\\sum_{i, j}{(G^l_{ij} - A^l_{ij})}$$ $$L_{style}(\\vec{a}, \\vec{x}) = \\sum^L_{l=0}{w_l E_l})$$\na : 입력이미지, x : 노이즈 A : 입력결과값, G : 노이즈 결과값 앞의 분수 : 값 정규화(너무 크지않도록) $w_l$ : 각 레이어에 대해 가중치 부여(하이퍼파라미터) 논문에서는 사용할 layer개수로 산술평균냄.(wl = 1/5) 손실함수 E를 보았을 때, 각 layer에 대한 gram matrix를 구하고 matrix 값을 비교하고 있다. 즉, filter간의 상관 관계 “결과값\"을 비교하는 것이므로, 각 filter 내부에서 값요소가 같을 필요는 없고(이게 같은건 content정보를 담겠다는 뜻…), 각 layer 에서 filter 끼리의 값 관계가 (G, A) 닮아야한다! 모델 분석 style loss\nstyle 이미지를 CNN모델에 쭉쭉 보내고, 각 layer에대해 Gram matrix계산. 노이즈에 대해서도 마찬가지로 계산. 각각의 오차를 합한 것이 style loss content loss\ncontent 이미지를 CNN모델에 쭉쭉 보내고, 노이즈에도 쭉쭉 보냄. 모든 feature에 대해 오차 합한 것이 content loss total loss\nstyle, content loss를 합한 후 노이즈의 gradient descent를 구해서 최적화한다. layer가 낮을 수록 content정보를 많이 갖고있고, 깊을 수록 style정보를 많이 담는 것을 알 수 있다.\n내 생각 style은 첫번째층부터 순차적으로 쌓는이유는, 결국에 정보를 최대한 많이 얻어야하고, noise 갱신하는 과정에서 기울기 손실? 줄이기 위해 다 사용 content는 각 layer마다 filter가 담고있는 정보가 다르므로(선, texture, object 등으로..) 서로간의 정보개입을 최대한 줄이기 위함이 아닌가 싶다… 코드 실습 라이브러리 호출 및 환경설정 # 필요한 PyTorch 라이브러리 불러오기 import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim import torchvision.transforms as transforms import torchvision.models as models import PIL import matplotlib.pyplot as plt import copy # GPU 장치 사용 설정 device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 이미지를 불러와 다운받아 텐서(Tensor) 객체로 변환하는 함수 def image_loader(img_path, imsize): loader = transforms.Compose([ transforms.Resize(imsize), # 이미지의 크기를 변경 transforms.ToTensor() # torch.Tensor 형식으로 변경 [0, 255] → [0, 1] ]) image = PIL.Image.open(img_path) # 네트워크 입력에 들어갈 이미지에 배치 목적의 차원(dimension) 추가 image = loader(image).unsqueeze(0) return image.to(device, torch.float) # GPU로 올리기 # torch.Tensor 형태의 이미지를 화면에 출력하는 함수 def imshow(tensor): # matplotlib는 CPU 기반이므로 CPU로 옮기기 image = tensor.cpu().clone() # torch.Tensor에서 사용되는 배치 목적의 차원(dimension) 제거 image = image.squeeze(0) # PIL 객체로 변경 image = transforms.ToPILImage()(image) # 이미지를 화면에 출력(matplotlib는 [0, 1] 사이의 값이라고 해도 정상적으로 처리) plt.imshow(image) plt.show() Image Reconstruction 실습 이미지를 손실값을 낮추는 방향으로 업데이트 하는것. MSE사용 # 목표 이미지(target image) 불러오기 img_path = './yasuo.jpg' target_image = image_loader(img_path, (512, 512)) imshow(target_image) # 동일한 크기의 노이즈 이미지 준비하기 noise = torch.empty_like(target_image).uniform_(0, 1).to(device) imshow(noise) loss = nn.MSELoss() iters = 100 lr = 1e4 print(\"[ Start ]\") imshow(noise) for i in range(iters): # required_grad 속성의 값을 True로 설정하여 해당 torch.Tensor의 연산을 추적 noise.requires_grad = True # 손실 함수에 대하여 미분하여 기울기(gradient) 계산 output = loss(noise, target_image) output.backward() # 계산된 기울기(gradient)를 이용하여 손실 함수가 감소하는 방향으로 업데이트 gradient = lr * noise.grad # 결과적으로 노이즈(perturbation)의 각 픽셀의 값이 [-eps, eps] 사이의 값이 되도록 자르기 noise = torch.clamp(noise - gradient, min=0, max=1).detach_() # 연산을 추적하는 것을 중단하기 위해 detach() 호출 if (i + 1) % 10 == 0: print(f'[ Step: {i + 1} ]') print(f'Loss: {output}') imshow(noise) Output hidden; open in https://colab.research.google.com to view. 실습할 이미지 불러오기 content_img = image_loader('./iu_content_1.jpg', (512, 640)) style_img = image_loader('./plot_style.jpg', (512, 640)) print(\"[ Content Image ]\") imshow(content_img) print(\"[ Style Image ]\") imshow(style_img) [ Content Image ] [ Style Image ] CNN 네트워크 불러오기. 사전학습된 VGG19 모델 불러옴 # vgg의 사전학습가중치로 모델 초기화하고, 평가모델로 일정한 출력 갖도록 설정. cnn = models.vgg19(pretrained=True).features.to(device).eval() print(cnn) /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead. warnings.warn( /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights. warnings.warn(msg) Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth 100%|██████████| 548M/548M [00:08\u003c00:00, 67.2MB/s] Sequential( (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace=True) (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU(inplace=True) (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (6): ReLU(inplace=True) (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (8): ReLU(inplace=True) (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace=True) (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (13): ReLU(inplace=True) (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (15): ReLU(inplace=True) (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (17): ReLU(inplace=True) (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (20): ReLU(inplace=True) (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (22): ReLU(inplace=True) (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (24): ReLU(inplace=True) (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (26): ReLU(inplace=True) (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (29): ReLU(inplace=True) (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (31): ReLU(inplace=True) (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (33): ReLU(inplace=True) (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (35): ReLU(inplace=True) (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) # vgg모델에 이미지 입력할 때, 정규화해서 넣도록 설정되어있으므로 입력 초기화 구현 cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device) cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device) class Normalization(nn.Module): def __init__(self, mean, std): super(Normalization, self).__init__() self.mean = mean.clone().view(-1, 1, 1) self.std = std.clone().view(-1, 1, 1) def forward(self, img): return (img - self.mean) / self.std Style Reconstruction 구현 주어진 noise를 특정 스타일의 이미지로 변하도록 구현 def gram_matrix(input): # a는 배치 크기, N는 특징 맵의 개수, (h, w)는 특징 맵의 차원을 의미 a, N, h, w = input.size() # 논문에서는 i = 특징 맵의 개수, j = 각 위치(position) features = input.view(a * N, h * w) # 행렬 곱으로 한 번에 Gram 내적 계산 가능 G = torch.mm(features, features.t()) # Normalize 목적으로 값 나누기 return G.div(a * N * h * w) # 스타일 손실(style loss) 계산을 위한 클래스 정의 # target을 초기화시켜서 gram_matrix만든다(A) # input을 집어넣고 gram_matrix화 시킨다.(G) # 둘 사이의 mse계산 class StyleLoss(nn.Module): def __init__(self, target_feature): super(StyleLoss, self).__init__() self.target = gram_matrix(target_feature).detach() def forward(self, input): G = gram_matrix(input) self.loss = F.mse_loss(G, self.target) return input style_layers = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5'] # 스타일 손실(style loss)을 계산하는 함수 def get_style_losses(cnn, style_img, noise_image): # 사전훈련된 vgg 모델 가져온다. cnn = copy.deepcopy(cnn) # 입력에 맞게 정규화 normalization = Normalization(cnn_normalization_mean, cnn_normalization_std).to(device) style_losses = [] # 가장 먼저 입력 이미지가 입력 정규화(input normalization)를 수행하도록 model = nn.Sequential(normalization) # 현재 CNN 모델에 포함되어 있는 모든 레이어를 확인하며 # model에다가 해당하는 층 이름 바꿔서 넣는다. i = 0 for layer in cnn.children(): if isinstance(layer, nn.Conv2d): i += 1 name = 'conv_{}'.format(i) elif isinstance(layer, nn.ReLU): name = 'relu_{}'.format(i) layer = nn.ReLU(inplace=False) elif isinstance(layer, nn.MaxPool2d): name = 'pool_{}'.format(i) elif isinstance(layer, nn.BatchNorm2d): name = 'bn_{}'.format(i) else: raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__)) model.add_module(name, layer) # 설정한 style layer까지의 결과를 이용해 style loss를 계산 if name in style_layers: target_feature = model(style_img).detach() style_loss = StyleLoss(target_feature) model.add_module(\"style_loss_{}\".format(i), style_loss) style_losses.append(style_loss) # 마지막 style loss 이후의 레이어는 사용하지 않도록 # 메모리사용량, 계산시간 줄이기 위해 (실제로 vgg모델에는 16개의 conv층이 있지만, 여기선 5개만 사용한다.) for i in range(len(model) - 1, -1, -1): if isinstance(model[i], StyleLoss): model = model[:(i + 1)] break return model, style_losses def style_reconstruction(cnn, style_img, input_img, iters): model, style_losses = get_style_losses(cnn, style_img, input_img) optimizer = optim.LBFGS([input_img.requires_grad_()]) print(\"[ Start ]\") imshow(input_img) # 하나의 값만 이용하기 위해 배열 형태로 사용 # global, local변수 문제때문에 걍 리스트로 저장해놓은듯. run = [0] while run[0] \u003c= iters: def closure(): input_img.data.clamp_(0, 1) optimizer.zero_grad() model(input_img) style_score = 0 for sl in style_losses: style_score += sl.loss # 가중치 곱해주는데,,, 다 똑같이하면 왜하는겨,,, style_score *= 1e6 style_score.backward() run[0] += 1 if run[0] % 50 == 0: print(f\"[ Step: {run[0]} / Style loss: {style_score.item()}]\") imshow(input_img) return style_score optimizer.step(closure) # 결과적으로 이미지의 각 픽셀의 값이 [0, 1] 사이의 값이 되도록 자르기 input_img.data.clamp_(0, 1) return input_img # 콘텐츠 이미지와 동일한 크기의 노이즈 이미지 준비하기 input_img = torch.empty_like(content_img).uniform_(0, 1).to(device) imshow(input_img) # style reconstruction 수행 output = style_reconstruction(cnn, style_img=style_img, input_img=input_img, iters=300) Output hidden; open in https://colab.research.google.com to view. style_layers = ['conv_1'] # 콘텐츠 이미지와 동일한 크기의 노이즈 이미지 준비하기 input_img = torch.empty_like(content_img).uniform_(0, 1).to(device) # style reconstruction 수행 output = style_reconstruction(cnn, style_img=style_img, input_img=input_img, iters=300) Output hidden; open in https://colab.research.google.com to view. style_layers = ['conv_4'] # 콘텐츠 이미지와 동일한 크기의 노이즈 이미지 준비하기 input_img = torch.empty_like(content_img).uniform_(0, 1).to(device) # style reconstruction 수행 output = style_reconstruction(cnn, style_img=style_img, input_img=input_img, iters=300) Output hidden; open in https://colab.research.google.com to view. Content reconstruction 실습 # 콘텐츠 손실(content loss) 계산을 위한 클래스 정의 # 앞에서의 손실 구하는 것과 동일. class ContentLoss(nn.Module): def __init__(self, target,): super(ContentLoss, self).__init__() self.target = target.detach() def forward(self, input): self.loss = F.mse_loss(input, self.target) return input # 여기서 원하는 층을 바꾸면 다른 층으로 실습해볼 수 있음! content_layers = ['conv_4'] # 콘텐츠 손실(content loss)을 계산하는 함수 # 앞에서 style loss 함수랑 똑같다. def get_content_losses(cnn, content_img, noise_image): cnn = copy.deepcopy(cnn) normalization = Normalization(cnn_normalization_mean, cnn_normalization_std).to(device) content_losses = [] # 가장 먼저 입력 이미지가 입력 정규화(input normalization)를 수행하도록 model = nn.Sequential(normalization) # 현재 CNN 모델에 포함되어 있는 모든 레이어를 확인하며 i = 0 for layer in cnn.children(): if isinstance(layer, nn.Conv2d): i += 1 name = 'conv_{}'.format(i) elif isinstance(layer, nn.ReLU): name = 'relu_{}'.format(i) layer = nn.ReLU(inplace=False) elif isinstance(layer, nn.MaxPool2d): name = 'pool_{}'.format(i) elif isinstance(layer, nn.BatchNorm2d): name = 'bn_{}'.format(i) else: raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__)) model.add_module(name, layer) # 설정한 content layer까지의 결과를 이용해 content loss를 계산 if name in content_layers: target_feature = model(content_img).detach() content_loss = ContentLoss(target_feature) model.add_module(\"content_loss_{}\".format(i), content_loss) content_losses.append(content_loss) # 마지막 content loss 이후의 레이어는 사용하지 않도록 for i in range(len(model) - 1, -1, -1): if isinstance(model[i], ContentLoss): model = model[:(i + 1)] break return model, content_losses def content_reconstruction(cnn, content_img, input_img, iters): model, content_losses = get_content_losses(cnn, content_img, input_img) optimizer = optim.LBFGS([input_img.requires_grad_()]) print(\"[ Start ]\") imshow(input_img) # 하나의 값만 이용하기 위해 배열 형태로 사용 run = [0] while run[0] \u003c= iters: def closure(): input_img.data.clamp_(0, 1) optimizer.zero_grad() model(input_img) content_score = 0 for cl in content_losses: content_score += cl.loss content_score.backward() run[0] += 1 if run[0] % 50 == 0: print(f\"[ Step: {run[0]} / Content loss: {content_score.item()}]\") imshow(input_img) return content_score optimizer.step(closure) # 결과적으로 이미지의 각 픽셀의 값이 [0, 1] 사이의 값이 되도록 자르기 input_img.data.clamp_(0, 1) return input_img # 콘텐츠 이미지와 동일한 크기의 노이즈 이미지 준비하기 input_img = torch.empty_like(content_img).uniform_(0, 1).to(device) # content reconstruction 수행 output = content_reconstruction(cnn, content_img=content_img, input_img=input_img, iters=300) Output hidden; open in https://colab.research.google.com to view. content_layers = ['conv_1'] # 콘텐츠 이미지와 동일한 크기의 노이즈 이미지 준비하기 input_img = torch.empty_like(content_img).uniform_(0, 1).to(device) # content reconstruction 수행 output = content_reconstruction(cnn, content_img=content_img, input_img=input_img, iters=300) Output hidden; open in https://colab.research.google.com to view. 깊은, 얕은 층의 차이에 따라 reconstruction의 정도가 다르다!!\nstyle은 더 깊을수록, content는 더 얕을수록 정확한 경향\nStyle Transfer 실습 content_layers = ['conv_4'] style_layers = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5'] # Style Transfer 손실(loss)을 계산하는 함수 def get_losses(cnn, content_img, style_img, noise_image): cnn = copy.deepcopy(cnn) normalization = Normalization(cnn_normalization_mean, cnn_normalization_std).to(device) content_losses = [] style_losses = [] # 가장 먼저 입력 이미지가 입력 정규화(input normalization)를 수행하도록 model = nn.Sequential(normalization) # 현재 CNN 모델에 포함되어 있는 모든 레이어를 확인하며 i = 0 for layer in cnn.children(): if isinstance(layer, nn.Conv2d): i += 1 name = 'conv_{}'.format(i) elif isinstance(layer, nn.ReLU): name = 'relu_{}'.format(i) layer = nn.ReLU(inplace=False) elif isinstance(layer, nn.MaxPool2d): name = 'pool_{}'.format(i) elif isinstance(layer, nn.BatchNorm2d): name = 'bn_{}'.format(i) else: raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__)) model.add_module(name, layer) # 설정한 content layer까지의 결과를 이용해 content loss를 계산 if name in content_layers: target_feature = model(content_img).detach() content_loss = ContentLoss(target_feature) model.add_module(\"content_loss_{}\".format(i), content_loss) content_losses.append(content_loss) # 설정한 style layer까지의 결과를 이용해 style loss를 계산 if name in style_layers: target_feature = model(style_img).detach() style_loss = StyleLoss(target_feature) model.add_module(\"style_loss_{}\".format(i), style_loss) style_losses.append(style_loss) # 마지막 loss 이후의 레이어는 사용하지 않도록 for i in range(len(model) - 1, -1, -1): if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss): break model = model[:(i + 1)] return model, content_losses, style_losses def style_transfer(cnn, content_img, style_img, input_img, iters): model, content_losses, style_losses = get_losses(cnn, content_img, style_img, input_img) optimizer = optim.LBFGS([input_img.requires_grad_()]) print(\"[ Start ]\") imshow(input_img) # 하나의 값만 이용하기 위해 배열 형태로 사용 run = [0] while run[0] \u003c= iters: def closure(): input_img.data.clamp_(0, 1) optimizer.zero_grad() model(input_img) content_score = 0 style_score = 0 for cl in content_losses: content_score += cl.loss for sl in style_losses: style_score += sl.loss style_score *= 1e5 loss = content_score + style_score loss.backward() run[0] += 1 if run[0] % 100 == 0: print(f\"[ Step: {run[0]} / Content loss: {content_score.item()} / Style loss: {style_score.item()}]\") imshow(input_img) return content_score + style_score optimizer.step(closure) # 결과적으로 이미지의 각 픽셀의 값이 [0, 1] 사이의 값이 되도록 자르기 input_img.data.clamp_(0, 1) return input_img # 콘텐츠(Content) 이미지와 스타일(Style) 이미지를 모두 준비합니다. content_img = image_loader('./iu_content_1.jpg', (512, 640)) style_img = image_loader('./plot_style.jpg', (512, 640)) print(\"[ Content Image ]\") imshow(content_img) print(\"[ Style Image ]\") imshow(style_img) [ Content Image ] [ Style Image ] # 콘텐츠 이미지와 동일한 크기의 노이즈 이미지 준비하기 input_img = torch.empty_like(content_img).uniform_(0, 1).to(device) # style transfer 수행 output = style_transfer(cnn, content_img=content_img, style_img=style_img, input_img=input_img, iters=900) Output hidden; open in https://colab.research.google.com to view. content_layers = ['conv_4'] style_layers = ['conv_1', 'conv_3', 'conv_5', 'conv_7', 'conv_9'] # 콘텐츠 이미지와 동일한 크기의 노이즈 이미지 준비하기 input_img = torch.empty_like(content_img).uniform_(0, 1).to(device) # style transfer 수행 output = style_transfer(cnn, content_img=content_img, style_img=style_img, input_img=input_img, iters=900) Output hidden; open in https://colab.research.google.com to view. ","wordCount":"2266","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://dobe0715.github.io/posts/style-transfer/"},"publisher":{"@type":"Organization","name":"블로그 홈","logo":{"@type":"ImageObject","url":"https://dobe0715.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dobe0715.github.io accesskey=h title="Home (Alt + H)"><img src=https://dobe0715.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://dobe0715.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://dobe0715.github.io/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dobe0715.github.io>Home</a>&nbsp;»&nbsp;<a href=https://dobe0715.github.io/posts/>Posts</a></div><h1 class=post-title>Image Style Transfer Using Convolutional Neural Networks review</h1><div class=post-meta>11 min&nbsp;·&nbsp;2266 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/style%20transfer.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><h1 id=review--image-style-transfer-using-convolutional-neural-networks>Review : Image Style Transfer Using Convolutional Neural Networks<a hidden class=anchor aria-hidden=true href=#review--image-style-transfer-using-convolutional-neural-networks>#</a></h1><ul><li>딥러닝을 이용하여 style을 합성을 시도한 초기 모델.</li></ul><h2 id=0-딥러닝-모델>0. 딥러닝 모델<a hidden class=anchor aria-hidden=true href=#0-딥러닝-모델>#</a></h2><ul><li>사전에 학습되어있는 VGG-19를 사용.</li><li>이중에서 5개의 conv계층 가져옴.</li><li>노이즈($\vec{x}$)와 실제 이미지 사이의 loss를 줄여 노이즈를 실제 이미지로 변환하는 과정으로 추론.</li></ul><h2 id=1-목적함수>1. 목적함수<a hidden class=anchor aria-hidden=true href=#1-목적함수>#</a></h2><ul><li>각각의 loss를 설계하는데에 있어서 CNN의 feature map의 성질을 적극 활용하였다.<ul><li>층이 깊어질 수록, chanel수는 증가하고, filter크기는 감소한다!</li><li>층이 깊어질 수록, style은 많이 담고, content는 적게담는다!</li></ul></li><li>content는 filter에서의 구체적인 값, style은 filter간의 분포도 값에 대응 시켰다.<br></li></ul><p>$F^l \in R^{N_l \times M_l}$</p><p>앞으로 이 값들을 계속해서 사용한다.</p><h3 id=11-content-loss>1.1 Content Loss<a hidden class=anchor aria-hidden=true href=#11-content-loss>#</a></h3><ul><li>그림의 내용(물체의 형태, 위치)에 대한 목적함수</li></ul><p>$$L_{content}(\vec{p}, \vec{x}, l) = \cfrac{1}{2} \sum_{i, j}({F^l_{ij} - P^l_{ij}})^2$$</p><ul><li>p : 입력이미지, x : 노이즈</li><li>P : 입력결과값, F : 노이즈결과값</li><li>이미지 feature 위치가 같아지도록 한다고 볼 수 있다.</li></ul><h3 id=12-style-loss>1.2 Style Loss<a hidden class=anchor aria-hidden=true href=#12-style-loss>#</a></h3><ul><li>그림의 스타일에 대한 목적함수<ul><li><p>Gram matrix
$$G^l \in R^{N_l \times N_l}$$
$$G^l_{ij} = \sum_k{F^l_{ik} F^l_{jk}}$$</p><ul><li>$l$번째 레이어의 $i$와$j$번째 feature map의 correlation을 파악하는 척도.</li><li>matrix의 크기는 각 layer의 filter개수에 비례한다. 즉, 층이 깊어질 수록 Gram matrix의 크기가 커진다.</li></ul></li><li><p>Loss function
$$E_l = \cfrac{1}{4N^2_l M^2_l}\sum_{i, j}{(G^l_{ij} - A^l_{ij})}$$
$$L_{style}(\vec{a}, \vec{x}) = \sum^L_{l=0}{w_l E_l})$$</p><ul><li>a : 입력이미지, x : 노이즈</li><li>A : 입력결과값, G : 노이즈 결과값</li><li>앞의 분수 : 값 정규화(너무 크지않도록)</li><li>$w_l$ : 각 레이어에 대해 가중치 부여(하이퍼파라미터)</li><li>논문에서는 사용할 layer개수로 산술평균냄.(wl = 1/5)</li><li><strong>손실함수 E를 보았을 때, 각 layer에 대한 gram matrix를 구하고 matrix 값을 비교하고 있다. 즉, filter간의 상관 관계 &ldquo;결과값"을 비교하는 것이므로, 각 filter 내부에서 값요소가 같을 필요는 없고(이게 같은건 content정보를 담겠다는 뜻&mldr;), 각 layer 에서 filter 끼리의 값 관계가 (G, A) 닮아야한다!</strong></li></ul></li></ul></li></ul><h3 id=모델-분석>모델 분석<a hidden class=anchor aria-hidden=true href=#모델-분석>#</a></h3><ul><li><p>style loss</p><ul><li>style 이미지를 CNN모델에 쭉쭉 보내고, 각 layer에대해 Gram matrix계산. 노이즈에 대해서도 마찬가지로 계산.</li><li>각각의 오차를 합한 것이 style loss</li></ul></li><li><p>content loss</p><ul><li>content 이미지를 CNN모델에 쭉쭉 보내고, 노이즈에도 쭉쭉 보냄.</li><li>모든 feature에 대해 오차 합한 것이 content loss</li></ul></li><li><p>total loss</p><ul><li>style, content loss를 합한 후 노이즈의 gradient descent를 구해서 최적화한다.</li></ul></li><li><p>layer가 낮을 수록 content정보를 많이 갖고있고, 깊을 수록 style정보를 많이 담는 것을 알 수 있다.</p></li></ul><h3 id=내-생각>내 생각<a hidden class=anchor aria-hidden=true href=#내-생각>#</a></h3><ul><li>style은 첫번째층부터 순차적으로 쌓는이유는, 결국에 정보를 최대한 많이 얻어야하고, noise 갱신하는 과정에서 기울기 손실? 줄이기 위해 다 사용</li><li>content는 각 layer마다 filter가 담고있는 정보가 다르므로(선, texture, object 등으로..) 서로간의 정보개입을 최대한 줄이기 위함이 아닌가 싶다&mldr;</li></ul><h1 id=코드-실습>코드 실습<a hidden class=anchor aria-hidden=true href=#코드-실습>#</a></h1><h2 id=라이브러리-호출-및-환경설정>라이브러리 호출 및 환경설정<a hidden class=anchor aria-hidden=true href=#라이브러리-호출-및-환경설정>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 필요한 PyTorch 라이브러리 불러오기</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn.functional</span> <span class=k>as</span> <span class=nn>F</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.optim</span> <span class=k>as</span> <span class=nn>optim</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torchvision.transforms</span> <span class=k>as</span> <span class=nn>transforms</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torchvision.models</span> <span class=k>as</span> <span class=nn>models</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>PIL</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>copy</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># GPU 장치 사용 설정</span>
</span></span><span class=line><span class=cl><span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&#34;cpu&#34;</span><span class=p>)</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 이미지를 불러와 다운받아 텐서(Tensor) 객체로 변환하는 함수</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>image_loader</span><span class=p>(</span><span class=n>img_path</span><span class=p>,</span> <span class=n>imsize</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>loader</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=n>transforms</span><span class=o>.</span><span class=n>Resize</span><span class=p>(</span><span class=n>imsize</span><span class=p>),</span> <span class=c1># 이미지의 크기를 변경</span>
</span></span><span class=line><span class=cl>        <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>()</span> <span class=c1># torch.Tensor 형식으로 변경 [0, 255] → [0, 1]</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>image</span> <span class=o>=</span> <span class=n>PIL</span><span class=o>.</span><span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>img_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 네트워크 입력에 들어갈 이미지에 배치 목적의 차원(dimension) 추가</span>
</span></span><span class=line><span class=cl>    <span class=n>image</span> <span class=o>=</span> <span class=n>loader</span><span class=p>(</span><span class=n>image</span><span class=p>)</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>image</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>float</span><span class=p>)</span> <span class=c1># GPU로 올리기</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># torch.Tensor 형태의 이미지를 화면에 출력하는 함수</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>imshow</span><span class=p>(</span><span class=n>tensor</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># matplotlib는 CPU 기반이므로 CPU로 옮기기</span>
</span></span><span class=line><span class=cl>    <span class=n>image</span> <span class=o>=</span> <span class=n>tensor</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>clone</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># torch.Tensor에서 사용되는 배치 목적의 차원(dimension) 제거</span>
</span></span><span class=line><span class=cl>    <span class=n>image</span> <span class=o>=</span> <span class=n>image</span><span class=o>.</span><span class=n>squeeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># PIL 객체로 변경 </span>
</span></span><span class=line><span class=cl>    <span class=n>image</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>ToPILImage</span><span class=p>()(</span><span class=n>image</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 이미지를 화면에 출력(matplotlib는 [0, 1] 사이의 값이라고 해도 정상적으로 처리)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>image</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><h3 id=image-reconstruction-실습>Image Reconstruction 실습<a hidden class=anchor aria-hidden=true href=#image-reconstruction-실습>#</a></h3><ul><li>이미지를 손실값을 낮추는 방향으로 업데이트 하는것.</li><li>MSE사용</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 목표 이미지(target image) 불러오기</span>
</span></span><span class=line><span class=cl><span class=n>img_path</span> <span class=o>=</span> <span class=s1>&#39;./yasuo.jpg&#39;</span>
</span></span><span class=line><span class=cl><span class=n>target_image</span> <span class=o>=</span> <span class=n>image_loader</span><span class=p>(</span><span class=n>img_path</span><span class=p>,</span> <span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>512</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>imshow</span><span class=p>(</span><span class=n>target_image</span><span class=p>)</span>
</span></span></code></pre></div><p><img loading=lazy src=output_13_0.png alt=png></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 동일한 크기의 노이즈 이미지 준비하기</span>
</span></span><span class=line><span class=cl><span class=n>noise</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>empty_like</span><span class=p>(</span><span class=n>target_image</span><span class=p>)</span><span class=o>.</span><span class=n>uniform_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>imshow</span><span class=p>(</span><span class=n>noise</span><span class=p>)</span>
</span></span></code></pre></div><p><img loading=lazy src=output_14_0.png alt=png></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MSELoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>iters</span> <span class=o>=</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl><span class=n>lr</span> <span class=o>=</span> <span class=mf>1e4</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;[ Start ]&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>imshow</span><span class=p>(</span><span class=n>noise</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>iters</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># required_grad 속성의 값을 True로 설정하여 해당 torch.Tensor의 연산을 추적</span>
</span></span><span class=line><span class=cl>    <span class=n>noise</span><span class=o>.</span><span class=n>requires_grad</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 손실 함수에 대하여 미분하여 기울기(gradient) 계산</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=n>noise</span><span class=p>,</span> <span class=n>target_image</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 계산된 기울기(gradient)를 이용하여 손실 함수가 감소하는 방향으로 업데이트</span>
</span></span><span class=line><span class=cl>    <span class=n>gradient</span> <span class=o>=</span> <span class=n>lr</span> <span class=o>*</span> <span class=n>noise</span><span class=o>.</span><span class=n>grad</span>
</span></span><span class=line><span class=cl>    <span class=c1># 결과적으로 노이즈(perturbation)의 각 픽셀의 값이 [-eps, eps] 사이의 값이 되도록 자르기</span>
</span></span><span class=line><span class=cl>    <span class=n>noise</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>clamp</span><span class=p>(</span><span class=n>noise</span> <span class=o>-</span> <span class=n>gradient</span><span class=p>,</span> <span class=nb>min</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=nb>max</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>detach_</span><span class=p>()</span> <span class=c1># 연산을 추적하는 것을 중단하기 위해 detach() 호출</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=mi>10</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;[ Step: </span><span class=si>{</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=si>}</span><span class=s1> ]&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Loss: </span><span class=si>{</span><span class=n>output</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>imshow</span><span class=p>(</span><span class=n>noise</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>Output hidden; open in https://colab.research.google.com to view.
</code></pre><h3 id=실습할-이미지-불러오기>실습할 이미지 불러오기<a hidden class=anchor aria-hidden=true href=#실습할-이미지-불러오기>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>content_img</span> <span class=o>=</span> <span class=n>image_loader</span><span class=p>(</span><span class=s1>&#39;./iu_content_1.jpg&#39;</span><span class=p>,</span> <span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>640</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>style_img</span> <span class=o>=</span> <span class=n>image_loader</span><span class=p>(</span><span class=s1>&#39;./plot_style.jpg&#39;</span><span class=p>,</span> <span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>640</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;[ Content Image ]&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>imshow</span><span class=p>(</span><span class=n>content_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;[ Style Image ]&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>imshow</span><span class=p>(</span><span class=n>style_img</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>[ Content Image ]
</code></pre><p><img loading=lazy src=output_17_1.png alt=png></p><pre><code>[ Style Image ]
</code></pre><p><img loading=lazy src=output_17_3.png alt=png></p><h3 id=cnn-네트워크-불러오기>CNN 네트워크 불러오기.<a hidden class=anchor aria-hidden=true href=#cnn-네트워크-불러오기>#</a></h3><ul><li>사전학습된 VGG19 모델 불러옴</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># vgg의 사전학습가중치로 모델 초기화하고, 평가모델로 일정한 출력 갖도록 설정.</span>
</span></span><span class=line><span class=cl><span class=n>cnn</span> <span class=o>=</span> <span class=n>models</span><span class=o>.</span><span class=n>vgg19</span><span class=p>(</span><span class=n>pretrained</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span><span class=o>.</span><span class=n>features</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>cnn</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Downloading: &quot;https://download.pytorch.org/models/vgg19-dcbb9e9d.pth&quot; to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth
100%|██████████| 548M/548M [00:08&lt;00:00, 67.2MB/s]


Sequential(
  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU(inplace=True)
  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU(inplace=True)
  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (6): ReLU(inplace=True)
  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (8): ReLU(inplace=True)
  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (11): ReLU(inplace=True)
  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (13): ReLU(inplace=True)
  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (15): ReLU(inplace=True)
  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (17): ReLU(inplace=True)
  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (20): ReLU(inplace=True)
  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (22): ReLU(inplace=True)
  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (24): ReLU(inplace=True)
  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (26): ReLU(inplace=True)
  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (29): ReLU(inplace=True)
  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (31): ReLU(inplace=True)
  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (33): ReLU(inplace=True)
  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (35): ReLU(inplace=True)
  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)
</code></pre><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># vgg모델에 이미지 입력할 때, 정규화해서 넣도록 설정되어있으므로 입력 초기화 구현</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>cnn_normalization_mean</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mf>0.485</span><span class=p>,</span> <span class=mf>0.456</span><span class=p>,</span> <span class=mf>0.406</span><span class=p>])</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>cnn_normalization_std</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mf>0.229</span><span class=p>,</span> <span class=mf>0.224</span><span class=p>,</span> <span class=mf>0.225</span><span class=p>])</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Normalization</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>mean</span><span class=p>,</span> <span class=n>std</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>Normalization</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>mean</span> <span class=o>=</span> <span class=n>mean</span><span class=o>.</span><span class=n>clone</span><span class=p>()</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>std</span> <span class=o>=</span> <span class=n>std</span><span class=o>.</span><span class=n>clone</span><span class=p>()</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>img</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>(</span><span class=n>img</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>mean</span><span class=p>)</span> <span class=o>/</span> <span class=bp>self</span><span class=o>.</span><span class=n>std</span>
</span></span></code></pre></div><h3 id=style-reconstruction-구현>Style Reconstruction 구현<a hidden class=anchor aria-hidden=true href=#style-reconstruction-구현>#</a></h3><ul><li>주어진 noise를 특정 스타일의 이미지로 변하도록 구현</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>gram_matrix</span><span class=p>(</span><span class=nb>input</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># a는 배치 크기, N는 특징 맵의 개수, (h, w)는 특징 맵의 차원을 의미</span>
</span></span><span class=line><span class=cl>    <span class=n>a</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>h</span><span class=p>,</span> <span class=n>w</span> <span class=o>=</span> <span class=nb>input</span><span class=o>.</span><span class=n>size</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># 논문에서는 i = 특징 맵의 개수, j = 각 위치(position)</span>
</span></span><span class=line><span class=cl>    <span class=n>features</span> <span class=o>=</span> <span class=nb>input</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>a</span> <span class=o>*</span> <span class=n>N</span><span class=p>,</span> <span class=n>h</span> <span class=o>*</span> <span class=n>w</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 행렬 곱으로 한 번에 Gram 내적 계산 가능</span>
</span></span><span class=line><span class=cl>    <span class=n>G</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>mm</span><span class=p>(</span><span class=n>features</span><span class=p>,</span> <span class=n>features</span><span class=o>.</span><span class=n>t</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=c1># Normalize 목적으로 값 나누기</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>G</span><span class=o>.</span><span class=n>div</span><span class=p>(</span><span class=n>a</span> <span class=o>*</span> <span class=n>N</span> <span class=o>*</span> <span class=n>h</span> <span class=o>*</span> <span class=n>w</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl><span class=c1># 스타일 손실(style loss) 계산을 위한 클래스 정의</span>
</span></span><span class=line><span class=cl><span class=c1># target을 초기화시켜서 gram_matrix만든다(A)</span>
</span></span><span class=line><span class=cl><span class=c1># input을 집어넣고 gram_matrix화 시킨다.(G)</span>
</span></span><span class=line><span class=cl><span class=c1># 둘 사이의 mse계산</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>StyleLoss</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>target_feature</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>StyleLoss</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>target</span> <span class=o>=</span> <span class=n>gram_matrix</span><span class=p>(</span><span class=n>target_feature</span><span class=p>)</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=nb>input</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>G</span> <span class=o>=</span> <span class=n>gram_matrix</span><span class=p>(</span><span class=nb>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>loss</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>mse_loss</span><span class=p>(</span><span class=n>G</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>target</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>input</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>style_layers</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;conv_1&#39;</span><span class=p>,</span> <span class=s1>&#39;conv_2&#39;</span><span class=p>,</span> <span class=s1>&#39;conv_3&#39;</span><span class=p>,</span> <span class=s1>&#39;conv_4&#39;</span><span class=p>,</span> <span class=s1>&#39;conv_5&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 스타일 손실(style loss)을 계산하는 함수</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_style_losses</span><span class=p>(</span><span class=n>cnn</span><span class=p>,</span> <span class=n>style_img</span><span class=p>,</span> <span class=n>noise_image</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 사전훈련된 vgg 모델 가져온다.</span>
</span></span><span class=line><span class=cl>    <span class=n>cnn</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>deepcopy</span><span class=p>(</span><span class=n>cnn</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 입력에 맞게 정규화</span>
</span></span><span class=line><span class=cl>    <span class=n>normalization</span> <span class=o>=</span> <span class=n>Normalization</span><span class=p>(</span><span class=n>cnn_normalization_mean</span><span class=p>,</span> <span class=n>cnn_normalization_std</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>style_losses</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 가장 먼저 입력 이미지가 입력 정규화(input normalization)를 수행하도록</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=n>normalization</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 현재 CNN 모델에 포함되어 있는 모든 레이어를 확인하며</span>
</span></span><span class=line><span class=cl>    <span class=c1># model에다가 해당하는 층 이름 바꿔서 넣는다.</span>
</span></span><span class=line><span class=cl>    <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>layer</span> <span class=ow>in</span> <span class=n>cnn</span><span class=o>.</span><span class=n>children</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>i</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span> <span class=o>=</span> <span class=s1>&#39;conv_</span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span> <span class=o>=</span> <span class=s1>&#39;relu_</span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>layer</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(</span><span class=n>inplace</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span> <span class=o>=</span> <span class=s1>&#39;pool_</span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span> <span class=o>=</span> <span class=s1>&#39;bn_</span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=s1>&#39;Unrecognized layer: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>layer</span><span class=o>.</span><span class=vm>__class__</span><span class=o>.</span><span class=vm>__name__</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>.</span><span class=n>add_module</span><span class=p>(</span><span class=n>name</span><span class=p>,</span> <span class=n>layer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 설정한 style layer까지의 결과를 이용해 style loss를 계산</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>name</span> <span class=ow>in</span> <span class=n>style_layers</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>target_feature</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>style_img</span><span class=p>)</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>style_loss</span> <span class=o>=</span> <span class=n>StyleLoss</span><span class=p>(</span><span class=n>target_feature</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>.</span><span class=n>add_module</span><span class=p>(</span><span class=s2>&#34;style_loss_</span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>),</span> <span class=n>style_loss</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>style_losses</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>style_loss</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 마지막 style loss 이후의 레이어는 사용하지 않도록</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 메모리사용량, 계산시간 줄이기 위해 (실제로 vgg모델에는 16개의 conv층이 있지만, 여기선 5개만 사용한다.)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>model</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>model</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>StyleLoss</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=p>[:(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>model</span><span class=p>,</span> <span class=n>style_losses</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>style_reconstruction</span><span class=p>(</span><span class=n>cnn</span><span class=p>,</span> <span class=n>style_img</span><span class=p>,</span> <span class=n>input_img</span><span class=p>,</span> <span class=n>iters</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=p>,</span> <span class=n>style_losses</span> <span class=o>=</span> <span class=n>get_style_losses</span><span class=p>(</span><span class=n>cnn</span><span class=p>,</span> <span class=n>style_img</span><span class=p>,</span> <span class=n>input_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>LBFGS</span><span class=p>([</span><span class=n>input_img</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;[ Start ]&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>imshow</span><span class=p>(</span><span class=n>input_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 하나의 값만 이용하기 위해 배열 형태로 사용</span>
</span></span><span class=line><span class=cl>    <span class=c1># global, local변수 문제때문에 걍 리스트로 저장해놓은듯.</span>
</span></span><span class=line><span class=cl>    <span class=n>run</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=n>run</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>&lt;=</span> <span class=n>iters</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>def</span> <span class=nf>closure</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>input_img</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>clamp_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=p>(</span><span class=n>input_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>style_score</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>sl</span> <span class=ow>in</span> <span class=n>style_losses</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>style_score</span> <span class=o>+=</span> <span class=n>sl</span><span class=o>.</span><span class=n>loss</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 가중치 곱해주는데,,, 다 똑같이하면 왜하는겨,,,</span>
</span></span><span class=line><span class=cl>            <span class=n>style_score</span> <span class=o>*=</span> <span class=mf>1e6</span>
</span></span><span class=line><span class=cl>            <span class=n>style_score</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>run</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>run</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>%</span> <span class=mi>50</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;[ Step: </span><span class=si>{</span><span class=n>run</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=si>}</span><span class=s2> / Style loss: </span><span class=si>{</span><span class=n>style_score</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>}</span><span class=s2>]&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>imshow</span><span class=p>(</span><span class=n>input_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>style_score</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>closure</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 결과적으로 이미지의 각 픽셀의 값이 [0, 1] 사이의 값이 되도록 자르기</span>
</span></span><span class=line><span class=cl>    <span class=n>input_img</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>clamp_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>input_img</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 콘텐츠 이미지와 동일한 크기의 노이즈 이미지 준비하기</span>
</span></span><span class=line><span class=cl><span class=n>input_img</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>empty_like</span><span class=p>(</span><span class=n>content_img</span><span class=p>)</span><span class=o>.</span><span class=n>uniform_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>imshow</span><span class=p>(</span><span class=n>input_img</span><span class=p>)</span>
</span></span></code></pre></div><p><img loading=lazy src=output_25_0.png alt=png></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># style reconstruction 수행</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>style_reconstruction</span><span class=p>(</span><span class=n>cnn</span><span class=p>,</span> <span class=n>style_img</span><span class=o>=</span><span class=n>style_img</span><span class=p>,</span> <span class=n>input_img</span><span class=o>=</span><span class=n>input_img</span><span class=p>,</span> <span class=n>iters</span><span class=o>=</span><span class=mi>300</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>Output hidden; open in https://colab.research.google.com to view.
</code></pre><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>style_layers</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;conv_1&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c1># 콘텐츠 이미지와 동일한 크기의 노이즈 이미지 준비하기</span>
</span></span><span class=line><span class=cl><span class=n>input_img</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>empty_like</span><span class=p>(</span><span class=n>content_img</span><span class=p>)</span><span class=o>.</span><span class=n>uniform_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># style reconstruction 수행</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>style_reconstruction</span><span class=p>(</span><span class=n>cnn</span><span class=p>,</span> <span class=n>style_img</span><span class=o>=</span><span class=n>style_img</span><span class=p>,</span> <span class=n>input_img</span><span class=o>=</span><span class=n>input_img</span><span class=p>,</span> <span class=n>iters</span><span class=o>=</span><span class=mi>300</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>Output hidden; open in https://colab.research.google.com to view.
</code></pre><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>style_layers</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;conv_4&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c1># 콘텐츠 이미지와 동일한 크기의 노이즈 이미지 준비하기</span>
</span></span><span class=line><span class=cl><span class=n>input_img</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>empty_like</span><span class=p>(</span><span class=n>content_img</span><span class=p>)</span><span class=o>.</span><span class=n>uniform_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># style reconstruction 수행</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>style_reconstruction</span><span class=p>(</span><span class=n>cnn</span><span class=p>,</span> <span class=n>style_img</span><span class=o>=</span><span class=n>style_img</span><span class=p>,</span> <span class=n>input_img</span><span class=o>=</span><span class=n>input_img</span><span class=p>,</span> <span class=n>iters</span><span class=o>=</span><span class=mi>300</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>Output hidden; open in https://colab.research.google.com to view.
</code></pre><h3 id=content-reconstruction-실습>Content reconstruction 실습<a hidden class=anchor aria-hidden=true href=#content-reconstruction-실습>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 콘텐츠 손실(content loss) 계산을 위한 클래스 정의</span>
</span></span><span class=line><span class=cl><span class=c1># 앞에서의 손실 구하는 것과 동일.</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ContentLoss</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>target</span><span class=p>,):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>ContentLoss</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>target</span> <span class=o>=</span> <span class=n>target</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=nb>input</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>loss</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>mse_loss</span><span class=p>(</span><span class=nb>input</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>target</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>input</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 여기서 원하는 층을 바꾸면 다른 층으로 실습해볼 수 있음!</span>
</span></span><span class=line><span class=cl><span class=n>content_layers</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;conv_4&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 콘텐츠 손실(content loss)을 계산하는 함수</span>
</span></span><span class=line><span class=cl><span class=c1># 앞에서 style loss 함수랑 똑같다.</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_content_losses</span><span class=p>(</span><span class=n>cnn</span><span class=p>,</span> <span class=n>content_img</span><span class=p>,</span> <span class=n>noise_image</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>cnn</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>deepcopy</span><span class=p>(</span><span class=n>cnn</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>normalization</span> <span class=o>=</span> <span class=n>Normalization</span><span class=p>(</span><span class=n>cnn_normalization_mean</span><span class=p>,</span> <span class=n>cnn_normalization_std</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>content_losses</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 가장 먼저 입력 이미지가 입력 정규화(input normalization)를 수행하도록</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=n>normalization</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 현재 CNN 모델에 포함되어 있는 모든 레이어를 확인하며</span>
</span></span><span class=line><span class=cl>    <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>layer</span> <span class=ow>in</span> <span class=n>cnn</span><span class=o>.</span><span class=n>children</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>i</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span> <span class=o>=</span> <span class=s1>&#39;conv_</span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span> <span class=o>=</span> <span class=s1>&#39;relu_</span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>layer</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(</span><span class=n>inplace</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span> <span class=o>=</span> <span class=s1>&#39;pool_</span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span> <span class=o>=</span> <span class=s1>&#39;bn_</span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=s1>&#39;Unrecognized layer: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>layer</span><span class=o>.</span><span class=vm>__class__</span><span class=o>.</span><span class=vm>__name__</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>.</span><span class=n>add_module</span><span class=p>(</span><span class=n>name</span><span class=p>,</span> <span class=n>layer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 설정한 content layer까지의 결과를 이용해 content loss를 계산</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>name</span> <span class=ow>in</span> <span class=n>content_layers</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>target_feature</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>content_img</span><span class=p>)</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>content_loss</span> <span class=o>=</span> <span class=n>ContentLoss</span><span class=p>(</span><span class=n>target_feature</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>.</span><span class=n>add_module</span><span class=p>(</span><span class=s2>&#34;content_loss_</span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>),</span> <span class=n>content_loss</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>content_losses</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>content_loss</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 마지막 content loss 이후의 레이어는 사용하지 않도록</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>model</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>model</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>ContentLoss</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=p>[:(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>model</span><span class=p>,</span> <span class=n>content_losses</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>content_reconstruction</span><span class=p>(</span><span class=n>cnn</span><span class=p>,</span> <span class=n>content_img</span><span class=p>,</span> <span class=n>input_img</span><span class=p>,</span> <span class=n>iters</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=p>,</span> <span class=n>content_losses</span> <span class=o>=</span> <span class=n>get_content_losses</span><span class=p>(</span><span class=n>cnn</span><span class=p>,</span> <span class=n>content_img</span><span class=p>,</span> <span class=n>input_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>LBFGS</span><span class=p>([</span><span class=n>input_img</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;[ Start ]&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>imshow</span><span class=p>(</span><span class=n>input_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 하나의 값만 이용하기 위해 배열 형태로 사용</span>
</span></span><span class=line><span class=cl>    <span class=n>run</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=n>run</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>&lt;=</span> <span class=n>iters</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>def</span> <span class=nf>closure</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>input_img</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>clamp_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=p>(</span><span class=n>input_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>content_score</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>cl</span> <span class=ow>in</span> <span class=n>content_losses</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>content_score</span> <span class=o>+=</span> <span class=n>cl</span><span class=o>.</span><span class=n>loss</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>content_score</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>run</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>run</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>%</span> <span class=mi>50</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;[ Step: </span><span class=si>{</span><span class=n>run</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=si>}</span><span class=s2> / Content loss: </span><span class=si>{</span><span class=n>content_score</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>}</span><span class=s2>]&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>imshow</span><span class=p>(</span><span class=n>input_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>content_score</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>closure</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 결과적으로 이미지의 각 픽셀의 값이 [0, 1] 사이의 값이 되도록 자르기</span>
</span></span><span class=line><span class=cl>    <span class=n>input_img</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>clamp_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>input_img</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 콘텐츠 이미지와 동일한 크기의 노이즈 이미지 준비하기</span>
</span></span><span class=line><span class=cl><span class=n>input_img</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>empty_like</span><span class=p>(</span><span class=n>content_img</span><span class=p>)</span><span class=o>.</span><span class=n>uniform_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># content reconstruction 수행</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>content_reconstruction</span><span class=p>(</span><span class=n>cnn</span><span class=p>,</span> <span class=n>content_img</span><span class=o>=</span><span class=n>content_img</span><span class=p>,</span> <span class=n>input_img</span><span class=o>=</span><span class=n>input_img</span><span class=p>,</span> <span class=n>iters</span><span class=o>=</span><span class=mi>300</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>Output hidden; open in https://colab.research.google.com to view.
</code></pre><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>content_layers</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;conv_1&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c1># 콘텐츠 이미지와 동일한 크기의 노이즈 이미지 준비하기</span>
</span></span><span class=line><span class=cl><span class=n>input_img</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>empty_like</span><span class=p>(</span><span class=n>content_img</span><span class=p>)</span><span class=o>.</span><span class=n>uniform_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># content reconstruction 수행</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>content_reconstruction</span><span class=p>(</span><span class=n>cnn</span><span class=p>,</span> <span class=n>content_img</span><span class=o>=</span><span class=n>content_img</span><span class=p>,</span> <span class=n>input_img</span><span class=o>=</span><span class=n>input_img</span><span class=p>,</span> <span class=n>iters</span><span class=o>=</span><span class=mi>300</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>Output hidden; open in https://colab.research.google.com to view.
</code></pre><p><strong>깊은, 얕은 층의 차이에 따라 reconstruction의 정도가 다르다!!</strong><br><strong>style은 더 깊을수록, content는 더 얕을수록 정확한 경향</strong></p><h3 id=style-transfer-실습>Style Transfer 실습<a hidden class=anchor aria-hidden=true href=#style-transfer-실습>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>content_layers</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;conv_4&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>style_layers</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;conv_1&#39;</span><span class=p>,</span> <span class=s1>&#39;conv_2&#39;</span><span class=p>,</span> <span class=s1>&#39;conv_3&#39;</span><span class=p>,</span> <span class=s1>&#39;conv_4&#39;</span><span class=p>,</span> <span class=s1>&#39;conv_5&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Style Transfer 손실(loss)을 계산하는 함수</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_losses</span><span class=p>(</span><span class=n>cnn</span><span class=p>,</span> <span class=n>content_img</span><span class=p>,</span> <span class=n>style_img</span><span class=p>,</span> <span class=n>noise_image</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>cnn</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>deepcopy</span><span class=p>(</span><span class=n>cnn</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>normalization</span> <span class=o>=</span> <span class=n>Normalization</span><span class=p>(</span><span class=n>cnn_normalization_mean</span><span class=p>,</span> <span class=n>cnn_normalization_std</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>content_losses</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>style_losses</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 가장 먼저 입력 이미지가 입력 정규화(input normalization)를 수행하도록</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=n>normalization</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 현재 CNN 모델에 포함되어 있는 모든 레이어를 확인하며</span>
</span></span><span class=line><span class=cl>    <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>layer</span> <span class=ow>in</span> <span class=n>cnn</span><span class=o>.</span><span class=n>children</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>i</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span> <span class=o>=</span> <span class=s1>&#39;conv_</span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span> <span class=o>=</span> <span class=s1>&#39;relu_</span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>layer</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(</span><span class=n>inplace</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span> <span class=o>=</span> <span class=s1>&#39;pool_</span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span> <span class=o>=</span> <span class=s1>&#39;bn_</span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=s1>&#39;Unrecognized layer: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>layer</span><span class=o>.</span><span class=vm>__class__</span><span class=o>.</span><span class=vm>__name__</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>.</span><span class=n>add_module</span><span class=p>(</span><span class=n>name</span><span class=p>,</span> <span class=n>layer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 설정한 content layer까지의 결과를 이용해 content loss를 계산</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>name</span> <span class=ow>in</span> <span class=n>content_layers</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>target_feature</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>content_img</span><span class=p>)</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>content_loss</span> <span class=o>=</span> <span class=n>ContentLoss</span><span class=p>(</span><span class=n>target_feature</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>.</span><span class=n>add_module</span><span class=p>(</span><span class=s2>&#34;content_loss_</span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>),</span> <span class=n>content_loss</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>content_losses</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>content_loss</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 설정한 style layer까지의 결과를 이용해 style loss를 계산</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>name</span> <span class=ow>in</span> <span class=n>style_layers</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>target_feature</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>style_img</span><span class=p>)</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>style_loss</span> <span class=o>=</span> <span class=n>StyleLoss</span><span class=p>(</span><span class=n>target_feature</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>.</span><span class=n>add_module</span><span class=p>(</span><span class=s2>&#34;style_loss_</span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>),</span> <span class=n>style_loss</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>style_losses</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>style_loss</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 마지막 loss 이후의 레이어는 사용하지 않도록</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>model</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>model</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>ContentLoss</span><span class=p>)</span> <span class=ow>or</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>model</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>StyleLoss</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=p>[:(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>model</span><span class=p>,</span> <span class=n>content_losses</span><span class=p>,</span> <span class=n>style_losses</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>style_transfer</span><span class=p>(</span><span class=n>cnn</span><span class=p>,</span> <span class=n>content_img</span><span class=p>,</span> <span class=n>style_img</span><span class=p>,</span> <span class=n>input_img</span><span class=p>,</span> <span class=n>iters</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=p>,</span> <span class=n>content_losses</span><span class=p>,</span> <span class=n>style_losses</span> <span class=o>=</span> <span class=n>get_losses</span><span class=p>(</span><span class=n>cnn</span><span class=p>,</span> <span class=n>content_img</span><span class=p>,</span> <span class=n>style_img</span><span class=p>,</span> <span class=n>input_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>LBFGS</span><span class=p>([</span><span class=n>input_img</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;[ Start ]&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>imshow</span><span class=p>(</span><span class=n>input_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 하나의 값만 이용하기 위해 배열 형태로 사용</span>
</span></span><span class=line><span class=cl>    <span class=n>run</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=n>run</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>&lt;=</span> <span class=n>iters</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>def</span> <span class=nf>closure</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>input_img</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>clamp_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=p>(</span><span class=n>input_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>content_score</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>            <span class=n>style_score</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>cl</span> <span class=ow>in</span> <span class=n>content_losses</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>content_score</span> <span class=o>+=</span> <span class=n>cl</span><span class=o>.</span><span class=n>loss</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>sl</span> <span class=ow>in</span> <span class=n>style_losses</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>style_score</span> <span class=o>+=</span> <span class=n>sl</span><span class=o>.</span><span class=n>loss</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>style_score</span> <span class=o>*=</span> <span class=mf>1e5</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span> <span class=o>=</span> <span class=n>content_score</span> <span class=o>+</span> <span class=n>style_score</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>run</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>run</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>%</span> <span class=mi>100</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;[ Step: </span><span class=si>{</span><span class=n>run</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=si>}</span><span class=s2> / Content loss: </span><span class=si>{</span><span class=n>content_score</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>}</span><span class=s2> / Style loss: </span><span class=si>{</span><span class=n>style_score</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>}</span><span class=s2>]&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>imshow</span><span class=p>(</span><span class=n>input_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>content_score</span> <span class=o>+</span> <span class=n>style_score</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>closure</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 결과적으로 이미지의 각 픽셀의 값이 [0, 1] 사이의 값이 되도록 자르기</span>
</span></span><span class=line><span class=cl>    <span class=n>input_img</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>clamp_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>input_img</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 콘텐츠(Content) 이미지와 스타일(Style) 이미지를 모두 준비합니다.</span>
</span></span><span class=line><span class=cl><span class=n>content_img</span> <span class=o>=</span> <span class=n>image_loader</span><span class=p>(</span><span class=s1>&#39;./iu_content_1.jpg&#39;</span><span class=p>,</span> <span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>640</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>style_img</span> <span class=o>=</span> <span class=n>image_loader</span><span class=p>(</span><span class=s1>&#39;./plot_style.jpg&#39;</span><span class=p>,</span> <span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>640</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;[ Content Image ]&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>imshow</span><span class=p>(</span><span class=n>content_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;[ Style Image ]&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>imshow</span><span class=p>(</span><span class=n>style_img</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>[ Content Image ]
</code></pre><p><img loading=lazy src=output_40_1.png alt=png></p><pre><code>[ Style Image ]
</code></pre><p><img loading=lazy src=output_40_3.png alt=png></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 콘텐츠 이미지와 동일한 크기의 노이즈 이미지 준비하기</span>
</span></span><span class=line><span class=cl><span class=n>input_img</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>empty_like</span><span class=p>(</span><span class=n>content_img</span><span class=p>)</span><span class=o>.</span><span class=n>uniform_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># style transfer 수행</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>style_transfer</span><span class=p>(</span><span class=n>cnn</span><span class=p>,</span> <span class=n>content_img</span><span class=o>=</span><span class=n>content_img</span><span class=p>,</span> <span class=n>style_img</span><span class=o>=</span><span class=n>style_img</span><span class=p>,</span> <span class=n>input_img</span><span class=o>=</span><span class=n>input_img</span><span class=p>,</span> <span class=n>iters</span><span class=o>=</span><span class=mi>900</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>Output hidden; open in https://colab.research.google.com to view.
</code></pre><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>content_layers</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;conv_4&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>style_layers</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;conv_1&#39;</span><span class=p>,</span> <span class=s1>&#39;conv_3&#39;</span><span class=p>,</span> <span class=s1>&#39;conv_5&#39;</span><span class=p>,</span> <span class=s1>&#39;conv_7&#39;</span><span class=p>,</span> <span class=s1>&#39;conv_9&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c1># 콘텐츠 이미지와 동일한 크기의 노이즈 이미지 준비하기</span>
</span></span><span class=line><span class=cl><span class=n>input_img</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>empty_like</span><span class=p>(</span><span class=n>content_img</span><span class=p>)</span><span class=o>.</span><span class=n>uniform_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># style transfer 수행</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>style_transfer</span><span class=p>(</span><span class=n>cnn</span><span class=p>,</span> <span class=n>content_img</span><span class=o>=</span><span class=n>content_img</span><span class=p>,</span> <span class=n>style_img</span><span class=o>=</span><span class=n>style_img</span><span class=p>,</span> <span class=n>input_img</span><span class=o>=</span><span class=n>input_img</span><span class=p>,</span> <span class=n>iters</span><span class=o>=</span><span class=mi>900</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>Output hidden; open in https://colab.research.google.com to view.
</code></pre></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://dobe0715.github.io/posts/stable-diffusion/><span class=title>« Prev</span><br><span>High-Resolution Image Synthesis with Satent Diffusion Models(Stable Diffusion) review</span></a>
<a class=next href=https://dobe0715.github.io/posts/more-diffusion/><span class=title>Next »</span><br><span>Improved DDPM, Diffusion models beat GANs</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Image Style Transfer Using Convolutional Neural Networks review on twitter" href="https://twitter.com/intent/tweet/?text=Image%20Style%20Transfer%20Using%20Convolutional%20Neural%20Networks%20review&amp;url=https%3a%2f%2fdobe0715.github.io%2fposts%2fstyle-transfer%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Image Style Transfer Using Convolutional Neural Networks review on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fdobe0715.github.io%2fposts%2fstyle-transfer%2f&amp;title=Image%20Style%20Transfer%20Using%20Convolutional%20Neural%20Networks%20review&amp;summary=Image%20Style%20Transfer%20Using%20Convolutional%20Neural%20Networks%20review&amp;source=https%3a%2f%2fdobe0715.github.io%2fposts%2fstyle-transfer%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Image Style Transfer Using Convolutional Neural Networks review on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fdobe0715.github.io%2fposts%2fstyle-transfer%2f&title=Image%20Style%20Transfer%20Using%20Convolutional%20Neural%20Networks%20review"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Image Style Transfer Using Convolutional Neural Networks review on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fdobe0715.github.io%2fposts%2fstyle-transfer%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Image Style Transfer Using Convolutional Neural Networks review on whatsapp" href="https://api.whatsapp.com/send?text=Image%20Style%20Transfer%20Using%20Convolutional%20Neural%20Networks%20review%20-%20https%3a%2f%2fdobe0715.github.io%2fposts%2fstyle-transfer%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Image Style Transfer Using Convolutional Neural Networks review on telegram" href="https://telegram.me/share/url?text=Image%20Style%20Transfer%20Using%20Convolutional%20Neural%20Networks%20review&amp;url=https%3a%2f%2fdobe0715.github.io%2fposts%2fstyle-transfer%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Image Style Transfer Using Convolutional Neural Networks review on ycombinator" href="https://news.ycombinator.com/submitlink?t=Image%20Style%20Transfer%20Using%20Convolutional%20Neural%20Networks%20review&u=https%3a%2f%2fdobe0715.github.io%2fposts%2fstyle-transfer%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://dobe0715.github.io>블로그 홈</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
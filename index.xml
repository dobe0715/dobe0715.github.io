<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>블로그 홈</title>
    <link>https://dobe0715.github.io/</link>
    <description>Recent content on 블로그 홈</description>
    <image>
      <title>블로그 홈</title>
      <url>https://dobe0715.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://dobe0715.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 09 Oct 2023 17:29:30 +0900</lastBuildDate><atom:link href="https://dobe0715.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Imgtest</title>
      <link>https://dobe0715.github.io/posts/imgtest/</link>
      <pubDate>Mon, 09 Oct 2023 17:29:30 +0900</pubDate>
      
      <guid>https://dobe0715.github.io/posts/imgtest/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ConvNeXt review</title>
      <link>https://dobe0715.github.io/posts/convnext/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dobe0715.github.io/posts/convnext/</guid>
      <description>A ConvNet for the 2020s 참고링크
https://arxiv.org/abs/2201.03545 https://americanoisice.tistory.com/121 논문의 아이디어 기존에 computer vision에서는 &amp;ldquo;sliding window&amp;quot;기법이 주된방법이었다. 반면에 NLP분야에서는 transformer라는 엄청난 모델이 나왔고, 이를 CV와 결합하여 ViT라는 모델이 나오면서, 이 역시 SOTA를 밥먹듯이 하고있다..
Transformer에서 사용한 기술들을 ConvNet에 적용한다면 어떻게 될까?
이 때, ResNet만 가지고 발전시킨다.
ConvNet의 Modernizing ResNet-50/200 vs Swin-T/B으로 모델을 대응시켜 각각 FLOPs를 맞춰서 비교한다.
macro design 2) ResNeXt 3) inverted bottleneck 4) large kernel size 5) various layer-wise micro design 1.</description>
    </item>
    
  </channel>
</rss>
